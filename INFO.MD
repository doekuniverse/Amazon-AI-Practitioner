Implementar para buscar una base de datos de producto para poder por ejemplo contextualizar con la situación específica de algún cliente o puede incluso hacer una búsqueda de productos por ciertas características no como por ejemplo el color entonces de alguna manera ese es el problema que resolver para que rack funcione correctamente necesitamos una orquestador Entonces el orquestador es como tal este componente central que se encarga de hacer las consultas a nuestra base de datos de vectores y ya habíamos platicado la vez pasada sobre el tema de en bedings y alguien tiene todavía dudas con ese tema no recuerdan tan claramente me pueden levantar la mano y lo revisamos pero es realmente la base de datos de vectores la representación puntual que necesita nuestro modelo de lenguaje para poder acceder yo creo que muchos de ustedes probablemente se preguntan bueno Y por qué no puedo utilizar una base de datos relacional para hacer una búsqueda como lo haré en cualquier base de datos No yo tengo filas tengo columnas hago un query sql porque no lo puedo utilizar porque realmente el modelo no entiende esa información textual sino más bien tiene que estar en un formato específico y ese es el formato de vectores no Entonces eso es lo que hace el orquestador nos ayuda a tener como ese Proxy para poder recuperar la información y algo importante en mi modelo cuando yo hago una consulta primero obtengo la información de la Fuente hago esta búsqueda ya sea a través de internet ya sea a través de una app y ya sea a través de una base de datos de vectores y cuando tengo esa información ese contexto se alimenta por eso es recuperación aumentada porque estamos aumentando la capacidad de respuesta de nuestro modelo el modelo como tal solamente tiene conocimiento fundamental sobre ciertos temas pero cuando nosotros le inyectamos este contexto adicional entonces podemos mejorar la precisión de la respuesta vale eso es prácticamente lo que hace la arquitectura hasta aquí alguna pregunta con este tema muy bien excelente ahora Qué ventajas tiene trabajar con este patrón de diseño o esta arquitectura rag pues principalmente que me da información que siempre está reciente porque Recuerden que el modelo pre entrenado como tal es un modelo que se quedó con el conocimiento disponible hasta el momento en el que fue entrenado Sí entonces me permite siempre Tener información mucho más reciente de dónde la vaya a recuperar va a depender un poquito de cómo implemente morra pero realmente esa es una de las grandes ventajas y esto también nos ayuda a eliminar el efecto de alucinación en los proms que me responda cosas que suenan muy plausibles pero que no son precisas lo que hacemos Es que con este contexto yo puedo tener mucho más certidumbre más certeza de lo que me está respondiendo y en el demo que les mostré la vez pasada donde entregue directamente la consola de bedrock Crea una base de conocimiento con un poco ts3 y vimos la respuesta al momento de charlar con el documento es que me daba justamente como los como las referencias de donde obtuvo esa información esa es una de las ventajas de ra que nos ayuda a tomar decisiones mucho más seguras No sí la información cambia conforme va pasando el tiempo rack siempre va a recuperar información en cada solicitud entonces me permite Tener información más reciente piénsenlo por ejemplo en una tabla de pedidos si yo tengo varias órdenes que han hecho los clientes Pues si probablemente el cliente hace una consulta Al momento de hacer la compra va a ver que su pedido está pendiente de ser enviado pero si vuelve a hacer esa consulta después de dos días probablemente a través de un chatbot le va a decir que el pedido ya está en tránsito y En qué ubicación se encuentra Y si vuelve a preguntar después de 5 días quizás ya tenga mayor certidumbre por qué Porque ya sabemos en qué momento va a llegar y en qué horario lo podemos recoger Entonces nos permite adaptarnos mucho más a diversas situaciones porque los contextos pueden cambiar así como cambia el clima cambian también los datos cada vez que nosotros estamos actualizando con sistemas externos Y entonces rack se vuelve como esta herramienta que nos permite estar obteniendo información fresca y la transparencia también se vuelve un factor importante porque entonces yo le doy más certidumbre a mis usuarios de dónde estamos recuperando la información qué tan reciente es esa información si yo creo una solución por ejemplo para abogados el abogado puede revisar a través de qué ley de qué publicación de qué año estamos hablando y puede corregir al modelo En caso de que esa información no sea relevante Entonces es una herramienta que también nos da mucha okay Y nos puede ayudar para un montón de aplicaciones prácticamente cualquier tipo de aplicación que ustedes puedan imaginar puede implementarse realmente con rac y este es un poquito el demo que les mostré la vez pasada Cómo se llama el patrón rack directamente en la WS yo tengo la opción de implementarlo por mí mismo o incluso puedo hacerlo directamente a través del servicio de petrog en bedrock se llaman bases de conocimiento y lo que hace aquí es que nosotros podemos implementar estos flujos de trabajo rag directamente con bedrock Entonces como lo mostra la vez pasada yo entro a la consola voy a la parte de bedrock noblexpaces Y desde ahí puedo crear una base de datos de conocimiento o puedo referenciar una base de datos ya existente Y eso le va a permitir que entonces mi modelo pueda establecer una comunicación directa con esta base de conocimiento y en función de eso recuperar datos Okay de hecho incluso podríamos tener múltiples bases de conocimiento un escenario similar o un servicio Digamos que ya está preparado para hacer esto business ya habíamos hablado en capítulos anteriores deliver que lo que me permitiera ayudarme con tareas de desarrollo pero que ubisiness se enfoca más bien en preguntas y respuestas a nivel de negocio entonces me permite plantear una situación y que hubieses consulte esas bases de conocimiento y pueda darme respuestas Cuál es la ventaja de business que no necesito codificar absolutamente nada Todo es más alto nivel y tengo soluciones que me permiten desplegar estos agentes inteligentes dentro de las empresas si yo le estuviera que decir ahorita Cuál es uno de los principales casos de uso que veo que las empresas quieren implementar es justamente este tener agentes o tener bases de conocimiento que nos puedan ayudar en la toma de decisiones pero para esa toma de decisiones necesitamos consultar diferentes Fuentes privadas de conocimiento eso es como el problema que resuelve you business y la idea es que no tengamos que hacer nada de desarrollo entonces prácticamente Esa es la idea muy bien y ahora tenemos otras opciones también para mejorar la precisión y aquí tenemos tres categorías diferentes que podemos utilizar para los modelos estos modelos autos regresivos o los modelos pre entrenados no Recuerden que gpt significa generative Qué quiere decir que alguien ya pre entre no el modelo Sí si yo me voy por ejemplo por una solución más de tomar el control me tengo que ir hacia sech makermakery yo puedo crear mis propios Júpiter notebooks puedo utilizar distintas apis que me das atchmaker y crear mis modelos de Machine learning para propósitos muy específicos Como por ejemplo detectar fraudes este detectar anomalías clasificación este redes neuronales profundas para clasificar imágenes etcétera Pero a mí me toca entrenarlo sí Entonces digamos que ese sería un modelo entrenado completamente por mí en la en el área generativa tenemos más bien los modelos pre entrenados que son los modelos fundacionales por eso se llaman foundation models Entonces qué pasa si yo quiero tomar un modelo que ya tiene como este conocimiento general estas capacidades genéricas muy amplias en diferentes áreas pero yo quiero especializarlo en algo muy particular en ese caso nos toca trabajar con fine tuning o hacer un ajuste fino El Phantom en particularmente lo que hace es darle mayor relevancia y mayor precisión para una tarea en particular entonces quiere decir que yo continúo entrenándolo pero quiero hacer ajustes muy finos Ese es el fine toon ahorita vamos a revisar cada caso de manera independiente otro tipo de fine tuning es el instruction base en donde yo quiero que el modelo aprenda a seguir instrucciones de manera muy particular ese es un caso de inferencia muy específico porque no solamente estoy respondiendo toques de texto para complementar un texto para poder Traducir por ejemplo entre un idioma y otro sino más bien Quiero ver qué tan bueno es siguiendo instrucciones y otra opción se llama contingente en este caso nosotros seguimos entrenando el modelo con mayores recursos pero mayor precisión para un área de dominio completa bueno examinando el primer la primera técnica fine tuning qué es lo que estamos buscando aquí que el modelo haga una tarea en particular de manera sobresaliente les viene la mente algún caso o alguna aplicación que pudiéramos utilizar con fine tuning que ustedes hayan visto que ustedes quieran implementar por ejemplo sí me escuchas Gabriel en el chat adelante Sí sí te escucho compañero bueno por ejemplo para todos los temas de regulatorio y con playas en donde se necesite información actualizada y más enfocada a temas técnico legales por ejemplo muy bien muy bien Y entonces qué necesitaríamos Por ejemplo para entrenar un modelo que fuera un abogado mucho más sofisticado no que supiera resolver casos en un dominio particular porque si hablamos el contexto legal hay muchas áreas no en las que en las que podríamos desempeñarnos pero eso es lo que hace ya viene un gran modelo de lenguaje para poder especializarlo en un área que necesitaríamos literatura especializada muy bien necesitaríamos técnicamente datos etiquetados verdad recuerdan que eran los datos etiquetados rafa por acá nos dice nuevas capas me gusta me gusta que hay un caso de uso para especializarlo en prendas de vestir a mi gusto Me gusto sí aprendizaje supervisado Exacto cuando hablamos de datos etiquetados estamos hablando de un proceso supervisado entonces yo necesito Entonces si yo voy a especializar este modelo para efectos legales tengo que entrenarlo sobre un dataset en donde yo tenga datos etiquetados o sea contexto solución contexto solución sí depende Cuál es la tarea que yo le quiera dar si por ejemplo este fuera un chatbot que no responde sobre algunas preguntas y respuestas para una entidad de gobierno supongamos que yo quiero crear una empresa en mi país y para crear una empresa pues tengo que entrar a un sitio web hay algunas algunos países que te permiten hacerlo en internet tienes que buscar primero el uso de marca el uso fonético este determinar la composición accionaria este hay como varios estatutos que tenemos que cubrir no entonces si yo quisiera que este abogado se especializara por ejemplo en este tema mercantil mis datos etiquetados entonces tendrían que corresponder con preguntas y respuestas frecuentes que todos los clientes generalmente te hacen cuando quieren abrir una empresa Sí si si mi mi chatbot y mi modelo que voy a a entrenar con un proceso de fine tuning se va a especializar en ganar casos por ejemplo mercantiles mis datos etiquetados entonces tendrían que ser muchos ejemplos de sentencias pienso yo te contextos en los que hubo un un Pues no sé un contexto legal particular y cómo se ganó Cuáles fueron los argumentos entonces tengo que Mostrar un montón de casos donde se ganó muchos casos donde se perdió para qué Para que realmente en este fine tuning aprenda esos pesos ese esos patrones generales y entonces puedo hacer muy bueno ganando demandas en el futuro con datos que no ha visto con datos no etiquetados okay entonces eso es importante en el phantomín tengo que tener datos que me permitan a mí este entrenar para esa tarea en particular sí cuál puede ser aquí el la ventaja fíjense mejora el desempeño de la tarea con pocos datos y costo Porque en un proceso de Phantom yo no estoy construyendo un modelo desde cero sino más bien quiero ajustar para una pequeña actividad quiero que sea muy buena una en una tarea muy específica entonces representa menos datos menos tiempo de procesamiento menos infraestructura Entonces se refiere que es menor costo Pero quizás mi reto pueda ser encontrar datos de muy buena calidad Sí porque si yo quiero especializarlo en algo como decíamos que es este poder guiar a la gente para poder constituir una empresa Necesito un montón de ejemplos de Constitución de muchas empresas distintas en diferentes mercados con diferentes composiciones accionarias con un montón de situaciones para que realmente se pueda ajustar y pueda tener ese conocimiento especializado vale Pero si yo lo entrené para esa tarea y después le quiero pedir que haga un proceso distinto legal no va a ser bueno porque va a caer sobre conocimiento base que ya tiene vale aquí nos ponen como ejemplo una aplicación que quiera hacer análisis de sentimiento basado en reviews de películas Entonces qué es lo que necesitaríamos para hacer un find tuning poder ajustar el tema de los reviews Sí supongamos por ejemplo Que si yo ahorita le pregunto a un modelo de lenguaje no Oye recomiéndame una película que este drama y también que tenga que ver con ciencia ficción y que esté en la última década y que tenga al menos un actor importante y más o menos te doy un ejemplo Estas son las películas que me gustan voy a tener una respuesta en un single Shot bastante buena pero no va a ser especialista en recomendarme ese tipo de películas si yo quiero hacer un fine tuning el caso aquí sería conseguir un Data set de un montón de reviews por ejemplo de documentales y ajustar Este modelo para que se especialista recomendando documentales vale ese es el caso del y el fine tuning basado en instrucciones va a permitir hacer lo mismo pero basado en ejecutar ciertas acciones Ahora que estuve en reinvent de hecho estuve asistió un workshop para hacer un fine tuning de un modelo y justamente lo hicimos basado en instrucciones y me pareció súper interesante el tema no Cuál es la idea que tú puedas mostrarle con un Data set que puede ser tanto sintético como como orgánico tomas un modelo lo mandas a entrenar y eso nos tomó aproximadamente unos 15 minutos con 50,000 el volumen de datos que tenían 50,000 generados para poder ajustar en instrucciones y cuál fue la ventaja que entonces el modelo puede ejecutar acciones ya sobre un como caso muy particular y algo que a mí me vino a la mente me quedé pensando como dije en dónde lo podría yo aplicar no y me parece por ejemplo que un caso muy a Doc sería imagínense que yo me dedico a dar consultoría hacemos desarrollo web y a nuestros clientes les damos la capacidad de que puedan interactuar con diferentes pasarelas de compras piensen por ejemplo una pues empresa de tipo stripe Entonces strike si ustedes han visto lápiz tiene un montón de funcionalidades puedes dar de alta productos puedes crear paquetes puedes crear suscripciones suspender suscripciones Cancelar suscripciones agregar tipos de pago entonces cuando tú tienes esa necesidad de poner un bajo tus condiciones comerciales para decir Oye mi producto lo puedes utilizar pero a partir de aquí muestro una pantalla en la que agregas tu tarjeta y yo empiezo a monetizar quizás no sea tan fácil programarlo a través de un modelo de lenguaje verdad eso es algo como que hay que hacer de manera mucho más tradicional con programación mucho más dura bueno imagínense que entrenamos un modelo en el cual le mostramos ejemplos de un montón de startups un montón de sitios web de cómo se podrían generar suscripciones Y entonces mi modelo yo lo ajusto para que tenga este este find tuning Pero que sepa entonces muy bien Cómo utilizar las diferentes apis de stripe qué argumentos tiene que pasar qué parámetros está esperando entonces con muchos ejemplos de distintos modelos de suscripción o de pago de una sola vez nuestro modelo se podría ajustar para saber exactamente cómo son esas instrucciones a seguir vale para hacerlo de manera pues mucho más entonces Cuál será la ventaja que yo desde el usuario final le puedo dar una instrucción a mi modelo y decirle Oye Quiero vender pasteles entonces en mi tienda tengo un catálogo de 15 productos distintos con precios fijos pero quiero explorar o que el usuario también opte por una suscripción donde yo cada mes le mando dos productos por una tarifa no y que pueda cancelarlo cuando él lo quiera entonces si yo le mando esa instrucción como ya está find creo que va a ser el modelo es darme las especificaciones y el código en específico para poder implementar esa funcionalidad de cobros Esa es la ventaja de la instrucción base hay otro caso también de entrenamiento que se llama para entrenamiento continuado y a diferencia del pythony que vimos el continuo pre training es como utilizar algo que se llama transferencia de conocimiento en el cual nosotros ya tenemos un conocimiento base pero queremos seguir entrenando sobre un área mucho más grande por ejemplo finanzas por ejemplo salud Okay entonces cuál es la ventaja no tengo que construir un modelo desde cero con todos los costos y la infraestructura y todos los retos que eso representa sino más bien utilizo ya un modelo existente Como por ejemplo meta o Queen Sí y lo que hago es yo seguir entrenando sobre mi propia infraestructura con mis propios datos pero lo hago especialistas sobre un área mucho más grande no en una tarea en particular que es lo que da el find tuning sino más bien yo continúo entrenando con un dato set mucho más abierto para qué para que el modelo sea mucho más capaz de resolver ciertos tipos de problemas el caso aquí particular podría ser por ejemplo una compañía farmacéutica quiere mejorar su entendimiento de investigación médica y desarrollo de fármacos no Entonces con las características que tiene el modelo de lenguaje entiende algunos conceptos básicos Quizás hasta mucho más profundos sobre sobre esta área pero para poder desarrollar fármacos para poder dar recomendaciones necesitamos un Data séptimo mucho más robusto para poder especializarlo Entonces ese sería un caso por ejemplo de continuo vale estos tres casos vienen en el examen de ella y practitioner nos preguntan sobre rack nos preguntan sobre fine tuning y continuo pre trading entonces importante como diferenciar las las como pues las principales diferencias no rag A diferencia de del fine tuning y el pre training no requiere que tú uses infraestructura para crear un nuevo modelo rag utiliza el mismo modelo pero lo que hacemos Es agregarle una capa de búsqueda para que pueda recuperar información de dónde la recuperan de su base de datos de vectores Sí cómo llegaron los vectores a la base de datos a través de un modelo de incrustación se utiliza un modelo para hacer inferencia y otro modelo para incrustar cuando yo le meto mis datos textuales al modelo de incrustación representa y entonces estos dos modelos se complementan para poder dar respuestas por eso rajoy es tan popular porque no tengo que entrar en el detalle fino de cómo seguir entrenando un modelo o hacen un pre training más todo el costo de infraestructura y un montón de ejemplos sino más bien yo subo mis pdfs mis productos la documentación que yo necesito y rag es como la solución más rápida y más efectiva para poder tener este respuestas mucho más precisas prueba llegar hasta un. donde tan especialista si yo necesito un modelo mucho más especialista y aquí yo lo pensaría es más quiero competir y diferenciarme en el mercado tengo que pensar en una solución de fine tuning Sí por ejemplo yo he estado investigando mucho Sobre estos temas para temas educativos a mí me encantaría este desarrollar un modelo que pudiera tener como el contexto que nosotros tenemos en bootcampis y tus nosotros tenemos toda una metodología hemos hecho una investigación desde hace ya varios años en métodos de enseñanza y además se va cambiando constantemente no metacognición este diferentes técnicas de aprendizaje Entonces qué tal que yo tomo mis datos etiquetados y que generó un modelo en find tuning que es especialista por ejemplo en ayudarte a pasar exámenes de certificación en la WS sí no va a ser especialista en enseñanza general porque eso no va a funcionar para niños que están estudiando en la primaria o universitarios Sí si yo quisiera que tuviera muchos dominios de enseñanza me tendrá que ir a la parte de conchin y pre training que requeriría un dataset mucho más completo vale Ya son como las principales diferencias entonces todo esto estuvo muy enfocado a la parte de Cómo podemos Pues personalizar los modelos okay muy bien y esta gráfica de acá nos muestra cómo con servicios de awu s podríamos lograr cada una de estas diferentes estrategias Entonces fíjense si estoy tratando con rap yo puedo pensar por ejemplo en Amazon q developer business podrá ser una manera de poder pues interactuar con rap o los países que tiene este pero si en algún momento yo quiero por ejemplo ajustar un modelo o seguir haciendo pre entrenamiento continuar el entrenamiento puede utilizar las apis de bedrock Y en este caso lo puedo hacer tanto con bedrock como con seis Maker como que hay una este dualidad en esos dos temas no por ejemplo me pudiera ir a sechachmaker utilizar un Notebook que ya existe para continuar para entrenando un modelo y después desplegarlo hacia bedrock o puedo venir directamente desde bedrock y hacer algún proceso de pythony hacia sagemaker son las dos opciones y en el tercer caso es si yo necesito un mayor control por un montón de políticas que vamos a ver más adelante construir un modelo fundacional desde cero puede utilizar es como un conjunto de recetas para ejecutar soluciones de ia fíjense Maker sage Maker jump Start es como el lugar para arrancar sobre todo para personas que no tengan tanto contexto tecnológico sobre ciencia de datos eso es como el principal objetivo que tiene el John Stars entonces aquí yo puedo buscar por ejemplo en el catálogo diferentes plantillas a distintas soluciones y con unos cuantos clics voy entreno valido justo parámetros despliego manejo todo el proceso completo simplemente siguiendo como recetas Sí esa es la idea del jumpstar aquí podemos encontrar por ejemplo modelos fundacionales sí podemos encontrar algunos algoritmos ya específicos no como por ejemplo este computer Vision si quiero por ejemplo desplegar un modelo en dispositivo celulares y tengo que utilizar técnicas de cuantización para disminuir el tamaño y poder en beberlo en un dispositivo desconectado de la red puedo hacerlo si por ejemplo encontré este algún modelo bien interesante en jogging Face que es este estado del arte y quiero probarlo hacer investigación puedo hacerlo directamente desde aquí entonces nos da como este catálogo de soluciones para poder hacerlo entonces para poder hacer otra opción para poder determinar Qué tipo de modelo y qué solución existe ya en stagemaker hay vale muy bien cómo evaluamos el modelo bueno en bedrock por ejemplo podemos comparar modelos si ustedes recuerdan en la interfaz de Petro yo tengo la opción de comprar sí y en comprar creo que lo hice la vez pasada Yo lanzo un Bronx y le digo a ver Quiero probar este plan con meta y lo quiero probar también con Cloud y puedo ver por ejemplo tanto latencia cual se tardó más cuál se tardó menos y el tipo de respuesta que me dio entonces en función de eso yo puedo compararlos y eso es lo que hoy en día se hace bastante ejecutamos pruebas para poder medir por ejemplo las respuestas que nos da un modelo Okay otra opción para poder evaluar un modelo generativo es también tener feedback humano o sea incorporar personas que revisen aleatoriamente ciertas respuestas Y evalúen qué tan adoc es la respuesta que nos está dando un modelo Okay si me voy por ejemplo a seis Maker para poder evaluar modelos podemos utilizar sagemaker clarify con clarify podemos nosotros saber este qué tan justo está haciendo un modelo por ejemplo podemos obtener métricas a través de reportes para entender realmente cómo el modelo está trabajando en torno hacia la ética Okay y sagemaker ground truck nos permite tener datos base para poder comparar las respuestas que nos está dando un modelo contra la verdad real que tenemos entre nuestro datasette sí Si por ejemplo yo estuviera ahorita entrenando un modelo para poder diagnosticar enfermedades con Grant podemos tener cientos de casos ya documentados comparar que me está recomendando el modelo En qué caso Está en un falso positivo en tu caso me está diciendo que estoy enfermo En cuáles se equivocó y compararlos contra la base que ya tenemos eso es lo que hace Entonces es tener como una base fundamental para poder este inspeccionar las respuestas que nos dan modelo y en función de esos saber si está listo para llevarlo a producción en la parte de rack con bedrock podemos hacerlo con noblex bases así se llama rack directamente acá y hay algunos notebooks del lado de sagemaker para poder implementar rack incluso rack mucho más sofisticado en donde yo tenga bases de datos de vectores en diferentes sistemas que No necesariamente están Incluso en la WS o qué pasaría si por ejemplo yo implemente mi base de datos de vectores con postres en Aurora o lo tengo por ejemplo Open Search nos vamos a tener varios ejemplos que no solamente se interactúan con las opciones que trae bedrock sino más bien con otros componentes de infraestructura lo mismo por acá para la personalización en bedrock yo puedo hacer ajustes finos o continuar el entrenamiento y en Job Start yo tengo el completo control es más ahora algo que que se tiene como una característica muy interesante es Maker maker hyperpot Y hyperpot prácticamente lo que hace es que me permite es como si tuviera containers ya listos con toda la infraestructura en integrados con seis Maker para poder hacer entrenamiento a gran escala entonces de alguna manera recorta Los costos porque ya no tengo que desplegar infraestructura para hacer entrenamiento donde en algunos casos creo que es muy válido o muy necesario sino más bien en hyperpot tengo como una opción mucho más ad hoc y sencilla para poder paralizar trabajos no este disminuye el tiempo de entrenamiento y disminuye costos también entonces Esta es una de las grandes ventajas y está basado en tecnologías de contenedores no para la parte de implementación en bedrock Tenemos una gran ventaja hay apis para todo todo es una app entonces podemos interactuar de manera programática con bedrock en sagemaker y ahí tenemos que despegar infraestructura de cómputo a manera de balanceadores de carga y atrás del balanceador de carga están mis contenedores sirviendo inferencia entonces tengo mayor control sobre la infraestructura pero tengo que tomar más decisiones sobre el tipo de infraestructura ventajas por ejemplo que tenemos acá en el lado de Search Maker Qué pasa por ejemplo cuando ya tengo un modelo que es lo suficientemente robusto Este funciona correctamente pero con el paso del tiempo el modelo empieza a generar drift es cuando el modelo empieza a bajar su precisión conforme va pasando el tiempo y eso es un efecto muy normal en los modelos Por qué Porque la distribución de los datos cambia o los hábitos de consumo de nuestros usuarios también cambian Entonces por ejemplo pensemos en un caso un banco entre un modelo para detectar patrones este de fraude financiero de fraude bancario pero es entrenamiento lo hicimos Hace 6 meses y ahora resulta que los patrones de fraude cambiaron ya no son en la medianoche sino más bien Ahora son a las 10 de la noche sí las cantidades ahora también cambiaron la audiencia que está utilizando nuestro producto ya cambió porque tiene una edad y son más jóvenes Sí ese tipo de cosas van haciendo que los modelos se vayan alejando del beyline de desempeño que nos están dando eso le llamamos drift de un modelo Entonces por ejemplo en sagemaker yo puedo detectar el drift lo puedo hacer incluso con clarify y cuando detecto esto puedo entrenar otro nuevo modelo lanzarlos en producción de manera paralela y hacer Blue Green diployment estar probando los dos modelos al tiempo y medir con Cloud watch Cuáles tienen las métricas más precisas en inferencia y con el que mejore me quedo con ese modelo entonces puedo hacer despliegues Blue Green despliegues de tipo canario Release directamente en producción eso no es posible con bedrock en ver como tengo una Api solamente puedo mandar a llamar a través de Api Y eso le toca el código pero de este otro lado se ha hecho Maker yo tengo más control sobre la infraestructura para hacer rollbacks por ejemplo okay muy bien bueno fíjense aquí tenemos nuestro primer recurso para este curso Se los voy a compartir vamos a echarle un vistazo a esto vayan ingresando y este demo nos va a mostrar Cómo trabajamos con los modelos a través de la consola de bedrock yo lo voy a mostrar por acá por ese link guárdenlo sí Recuerden que tienen que entrar con su cuenta de skill builder y listo y aprovechar para iniciar sesión por acá Así que Denme un segundito para hacerlo listo recuerden que tienen este acceso a estos recursos en cualquier momento que lo necesiten voy a asegurarme de poner por aquí los subtítulos listo esos 6 minutitos Así que les voy a mostrar el video y ya lo discutimos cualquiera que tengan por favor no duden en preguntarme accesibilidad s experiment with them and Evening to your applications is the Technology playground speaking a playgrounds let's chat about the chat Last text playground you can Drive with different Language questions and see how they respond to your mother for the plateground Dance like motors that you have access to models you don't have Access You Will be Great out the playground also Let You quick and Friends This Means like temperature or How create of the mother Gods and stop he Which option finally And your prompt and She's Run two and Run Will a love you to text your problems with the selection es new from ever responde güey You're not metals use the last I go on on the right side of the interfaces to out of Disney Mo elevations from the left navigation menu and your mother Love all elevation tues create then Shoes Magic you Can't Select the mother you want to a Valley so Let your Matrix location will be stored no That you make need to can figured the folder for use dly You Can't to create and you backdrock service to you so much Shoes create your validation Job has been created wait for this Star is the change from and progress To completed This could take a Wild then Shoes they about education nameling the dashboard shows yours and Matrix a long with you for each you can use this information Alone with the result in your history bucked to the weather mother is up to your performance other key features of Amazon bedrock and could Amazon Bad Rock and alpaces this feature Of You Too logment foundation miles With Your companys privases to deliver more accurate And question My responses integrations for you amazon bedrock prizing hispace to the service you pay a fix price Apple this price inspecting and controlly Pay for the actually Used Job service with Close orcaces Where you want more tren Spanish and your I really later expenses for example I customer Station that ones is customery so Don't before experiment ask questions and learning you go perfecto Bueno aquí hay algunas cosas que creo que vale la pena mencionar fíjense bueno Antes que nada quiero preguntarles si tienen alguna duda esta parte de la interfaz creo que se los mostré en algunos de los ejemplos pero prácticamente el playground es donde yo puedo interactuar con bedrock directamente en la consola de adoles lo cual está bastante bien pero no es la única manera de hacerlo Cuál sería la otra opción si ustedes tienen una cuenta de aws o tiene un Access kim y tenemos habilitada este los modelos de bedrock con Júpiter notebooks y de hecho hay bastantes fíjese eso los pueden encontrar acá si nos vamos a Kid Hot ews aquí fíjense Tenemos un montón de ejemplos que pueden hacer lo mismo pueden ustedes ver el nivel de respuesta la latencia la cantidad de tokens pueden clickear un poquito los proms si es que es lo que necesitan y Aquí hay varios por ejemplo veamos un caso como este no sé si el multimodal o algo un poco más básico a ver este de introducción a bedrock no por ejemplo este es uno de hecho les puedo compartir también el repositorio para que cuando tengan oportunidad lo revisen ahí lo tienen en el chat vale entonces por ejemplo yo quiero probar directamente alguna de las apis para para Petro no me voy para acá y tengo varios notebooks por acá por ejemplo veamos este de invocar la Api que es uno de los más sencillos aquí la ventaja es que tengo que instalar nada y puedo ver Incluso el resultado Sí aquí viene con un poquito de documentación que se necesita Aquí ejecuto esta celda e instalo por ejemplo voto 3 L y voto call sí Y más adelante me dice Cuáles son las apis que estoy utilizando de beatro porque subimos en la presentación yo puedo utilizar apis o puedo irme a la parte de infraestructura entonces con bedrock todo es completamente un Api los tengo el metro aquí el bedrock y acá por ejemplo arrancó mi cliente y le pasó el pronto si creo un cliente para metro con algunas configuraciones no le dices si quiero que utilices un rol para hacer tal cosa te voy a proporcionar la región Entonces estos ejemplos también son bastante buenos y vamos a llegar a resultados similares a los anteriores hay algunos ejemplos que ven aquí también así súper básicos que te muestran por ejemplo el modo streaming de bedrock y vas viendo cómo van apareciendo todas las palabras para construir tus aplicaciones o incluso invocarlos de otra manera que es por ejemplo en modo Bach Entonces digamos que la ventaja del playground es que tenemos una interfaz web pero no es la única manera de poder probarlo Okay se acuerdan que una de las sesiones pasadas también Hablamos de los hiper parámetros que tenía petrog aquí podemos ver algunos de estos súper parámetros Como por ejemplo la longitud de la respuesta la temperatura que deseamos controlaba la creatividad y el Toca para limitar la cantidad de tokens totales que quiero que tenga mi frase Sí entonces esos dos nos ayudan para ajustar el tipo de respuesta esto normalmente no lo vemos en aplicaciones finales Por aquí sí lo podemos controlar y el pro de sistema que también ayuda para dar instrucciones de tipo System para que el modelo se prepare y sepa qué es lo que queremos hacer para que no sea como tan en frío y otra parte aquí interesante que vemos es este método de comparativa y vimos que cambió los parámetros de temperatura la respuesta se vuelven más creativa y algo importante que yo puedo medir Cuántos toques se utiliza para la entrada este texto se traduce a 15 toques de entrada y cuánto me generó de salida Entonces yo quisiera por ejemplo limitarlo puedo bajar este número de 502 una cantidad menor y algo muy importante para experiencia de usuario cuánto tiempo tomó en entregar el primer token de respuesta Esa es la latencia Okay entonces tengo que esperar hasta 10 segundos con este modelo hay modelos que son más performantes y es más a través de bedrock yo puedo adquirir capacidad reservada lo cual me permite tener inferencias mucho más rápidas entonces todo eso es como completamente controlable y en la parte de comparativa Aquí es donde ya podemos testear a ver este modelo Cómo responde a esta pregunta versus este otro modelo podemos medir por ejemplo diferencias en latencia en tipo de respuesta y podemos ajustar los mismos hiper parámetros para los dos eso es lo que hacemos aquí como que podemos los dos modelos y hacemos pruebas finales de donde nosotros determinamos Qué modelo es el que nos está respondiendo mejor Okay entonces son como algunos.s evaluaciones nos ayuda a poder especificar contra diferentes Marcos cómo está funcionando un modelo y cuál sería como la real necesidad de esto cuando yo tengo ya un modelo en producción y una solución tengo si distintas preguntas no Qué pasaría si sale una nueva versión del modelo algo que notamos normalmente en cuanto sale una una nueva versión de modelos que las respuestas varían completamente entre un modelo y otro entonces para poder tener como esa garantía de que esas pruebas están sobre respondiendo los mismos textos o qué tanto están diferendo podemos utilizar model evaluation y podemos estar ejecutarlas ejecutándolas como constantemente para ver realmente qué tanta diferencia hay entre una versión de un modelo y otro para eso es justamente los trabajos de evaluación Vale y todo esto se puede automatizar las bases de conocimiento que les mostré la vez pasada subimos un documento y conversamos con nuestro documento puedo ponerlo Incluso en un boquete S3 Y esto es un patrón rag como tal directamente es de Pedro Okay y una ventaja Es que la respuesta voy a ver justamente estos.s en donde me dice De dónde obtuvo la respuesta para que yo tenga la certeza de que no está alucinando Okay hasta ahí tuvieron alguna duda con esta demostración qué les pareció bueno bueno me gusta Okay perfecto la verdad es que beso está muy bien pensado yo pienso es muy fácil integrarlo a tus soluciones hay muchas opciones para hacerlo y nos da mucha flexibilidad Perdón no nada más nos quedamos como pegados con un modelo con una implementación si no podemos cambiarlo de acuerdo a nuestras necesidades y es una gran ventaja no entonces ahí lo tenemos a ver primera pregunta de este módulo no Cuál es la principal ventaja de utilizar generation Comparado a un modelfine tuning la respuesta a dice los procesos rac consultan más rápido que utilizar este incrustaciones vectoriales como precomputadas no Esa es la primera vemos la segunda rac permite que las bases de datos o las actualizaciones a las bases de datos se hagan sin tener que reentrenar el modelo es como una buena no la número c rack automáticamente mejora los modelos o las capacidades de los modelos de lenguaje y la cuarta rack nos da respuestas más consistentes entre múltiples consultas por ella vi Muchas veces la ven se quién da más a la B también por Eddy y la C muy bien pues estamos en lo correcto la opción más a Doc sería la B Sí yo creo que este es el mayor valor en la la a la podemos descartar porque no quiere decir que las consultas que hacemos a rack responde más rápido al contrario se van a retardar más la latencia siempre va a ser más alta con ra por qué porque tenemos que consultar un sistema independiente para poder como retroalimentar el pront y así que el modelo Pues de una respuesta mucho más completa entonces realmente nunca va a ser más rápido no la c mejora las capacidades del modelo Yo diría que no mejora las capacidades del modelo sino más bien le da un mejor contexto al modelo sí creo que sería eso que sí le daría una mejor capacidad al modelo un find tuning o un training Sí vale muy bien perfecto vamos con la pregunta número 2 dice en un sistema rack Qué componente administra el proceso de búsqueda y enriquece los pros con el contexto relevante por cuál opción se van muy bien por ahí veo dos opciones dos a ver vamos a regresar a la arquitectura para verlo el componente que se encarga de orquestar todo esto es justamente el orquestador vean como el orquestador está como en medio de todo sí algo que está interesante en bedrock cuando ya creamos agentes es que podemos ver todo el proceso podemos ver por ejemplo el pron que mandó el usuario el proceso de decisión que tomó el orquestador como consulta el sistema externo que en este caso sería la base de datos de vectores que devuelve ese sistema y después Cómo se enriquece el proms eso es completamente auditable nosotros podemos ver toda esa traza con logs directamente en la consola Entonces ese es como el trabajo del orquestador vale Muy bien excelente Entonces era la opción número 2 para esta No aquí estamos en este caso sería efectivamente el orquestador coordina las búsquedas hacia las bases de datos vale se encarga de pasar ese fragmento de información al prompt para ahora sí tener una respuesta mucho más completa al modelo si hacemos la consulta al modelo después de recuperar los fragmentos de información vale muy bien Bueno este segundo módulo ya está enfocado más hacia allá responsable que también son las áreas importantes para el examen pero también muy importantes en la implementación sí Cuáles son los principios importantes de responsabilidad y de hecho tenemos una página de esto en la documentación aws general entonces son las prácticas responsables Sí aquí están entonces fíjense en español normalmente estos términos se llaman equidad explicabilidad privacidad seguridad sí controlabilidad gobernanza transparencia vale esto es importante entonces ahorita vamos a platicar un poquito de esto fíjense los principales como dimensiones que deberíamos de considerar siempre es bueno tener un framework No porque yo creo que cuando hablamos de seguridad pues es un término muy ambiguo y que tiene muchas perspectivas diferentes entonces lo que para mí es ejecutar ya responsable probablemente para otro equipo no lo es para una empresa en un contexto quizás no lo es lo mismo para otras entonces necesitamos tener un framework para poder alinearnos estas prácticas responsables entonces en qué nos tenemos que enfocar Cuando hacemos soluciones de ia en negativa el primero protección de personas y datos segundo ser abiertos con el uso de la ia así como nosotros entramos una página web y en esa página web dice que podemos solicitar por ejemplo una copia de nuestra información saber cómo está utilizando esa empresa la información también nos van a preguntar el día de mañana Oye Explícame Cómo llegaste a esta conclusión Dame transparencia de saber qué fue lo que pasó con mi solicitud entonces ese sí era responsable Okay tener esa apertura con el usuario final y también estar administrando constantemente las operaciones ya que estamos trabajando ese es el control y el gobierno este tema de Five Nights se refiere a dos temas muy muy importantes Lo principal es disminuir la posibilidad de que una guía tenga resultados distintos para diferentes grupos poblacionales O sea que sea muy justo para poder dar una decisión hacia hombres y mujeres hacia una etnia y otra etnia hacia un país y otro país Sí como que no infiera no se sesgue Ese es como el tema de esta práctica justamente tener esa justicia a nivel del modelo y de hecho tenemos servicio simétricas que nos ayudan a testear qué tan justos somos otra parte importante del sesgo es el sesgo por los datos qué es lo que les mencioné hace un momento hoy yo puedo tener un modelo con mis datos etiquetados y el modelo Tiene una precisión del 98% pues muy bueno no hay un 2% que probablemente está saliendo que las clasificaciones no son correctas Pero qué pasa si ese modelo conforme va pasando el tiempo empieza a disminuir y se va el 95 y después al 90 entonces estoy teniendo un sesgo en los datos Qué necesito volver a reentrenar y hay un montón de hipótesis que pueden suceder aquí uno tengo pocos datos dos tengo datos que no representan bien a las diferentes clases que tengo tres hay un desbalance en las clases cuatro hay un comportamiento distinto de datos diferentes mi aplicación entonces tengo que reentrenar sí otro tipo de sesgo que podemos llegar a tener también es por la elección de un algoritmo Entonces cuando trabajamos con modelos de lenguaje no tenemos mucha elección sobre el algoritmo pero cuando trabajamos con soluciones de Machine learning sí tenemos completamente esa decisión si yo voy a utilizar por ejemplo una máquina de soporte vectorial versus un este árbol aleatorio sí o un modelo de regresión versus un modelo de clasificación etcétera va a tener un impacto importante entonces tengo que entender mucho la naturaleza de mis datos Entonces eso es importante el vallas por interacción se puede dar también porque no representa muy bien a distintos grupos demográficos entonces piense por ejemplo que yo quiero aplicar una universidad y en la universidad ya están llevando estos procesos a través de ia pero yo vengo de un de un pueblo de una ciudad que no es la ciudad principal que tenemos este una cantidad de personas muy pequeña muy reducida una poca representatividad en los datos que se utilizaron para el entrenamiento Lo más seguro es que a mí me denieguen el ingreso de esa universidad están de acuerdo Entonces eso puede llegar a suceder también podemos tener un efecto de amplificación social por qué Porque suceden cosas en el contexto en las noticias que pueden afectar a distintos grupos sí piensen por ejemplo qué pasa con los usuarios que somos latinos versos los usuarios asiáticos versus los usuarios de este Europa por ejemplo central sí quizás hay diferentes noticias y cosas que si yo lanzo un modelo para que aprenda con datos que están ahí afuera en internet se puede sesgar ante ese tipo de situaciones que pueden ser políticas pueden ser este hasta una pandemia podría afectar un algoritmo no Piénsalo Desde esa manera la seguridad es garantizar que cuando nosotros interactuamos con un modelo nos sentamos seguros y que sea seguro el uso no no sé si han visto de repente Algunos videos que están de repente circulando en internet no y le preguntan a Chad gpt Oye chat gpt seguro que me tome este agua con cloro y tal si es una excelente idea porque el cloro es muy bueno para limpiar superficies todo ya que la persona está acá en el doctor en el hospital este Oye cómo me puedo curar eso Ah sí Bueno te voy a dar una recomendación porque no deberías de tomar cloro no tú sabes como que los los modelos tienen a ser muy condescendientes entonces con nosotros diseñamos la seguridad en un modelo tenemos que estructurar muy bien Cuáles son esos esas barandillas o esos límites en los cuales el modelo Tiene que trabajar entonces esa es la seguridad no Muchas personas hoy estamos utilizando y porque yo lo he intentado también como consejeros no que que nos dé alguna recomendación que me ayude a interpretar mis sueños que que incluso hasta reemplazarlo como si fuera un psicólogo esas prácticas no pueden ser seguras para toda la población entonces hay poblaciones que son muy susceptibles Y entonces esto es un uso que no no sería muy seguro no piensen en eso y el caso que más me encuentro con empresas es la privacidad y la seguridad todas las empresas están un poco como resistentes a utilizar ia Por qué Porque no saben que se está haciendo con sus datos Y eso es eso es relevante No si nosotros asumimos que hoy en día las principales empresas que están generando modelos de lenguaje están en Estados Unidos están en Asia pues sabemos que la soberanidades esos datos Entonces se mantiene dentro de Estados Unidos y si en algún momento algún país cambia sus políticas y dejan de ser abiertas o cambia la manera en la que analizan la información pues eso no no respeta la privacidad de las personas no por eso hoy se habla tanto que los gobiernos deberían de tener también sus propios modelos de lenguaje que entiendan contextos específicos que entiendan el panorama legal cultural de cada país para que utilicemos esos modelos pero una empresa hoy en día no utilizar modelos abiertos ni modelos de terceros sino más bien quieren tener infraestructura privada y segura y aquí es donde entra bedrock porque en la WS ellos no pueden ver los promos que nosotros estamos enviando ellos no tienen acceso por ejemplo a los documentos que subimos una base de conocimientos nosotros Podemos agregar controles adicionales por ejemplo para encriptar los datos para auditarlos y todo eso se ejecuta dentro de un sandbox seguro Esa es la ventaja de trabajar con ella dentro de la West otra otra ventaja puede ser por ejemplo la velocidad y la robustez entonces aquí lo que buscamos es que las salidas sean consistentes y que no varían mucho entre un caso y otro okay cómo lo hacemos testeando constantemente los modelos y ver qué tanto difieren entre uno y otro si yo hoy estoy trabajando con bedrock utilizando por ejemplo antropic y Quiero probar una versión distinta por ejemplo con Queen o quiere utilizar una versión de meta puedo utilizar esas pruebas este para ver qué tanto difieren las respuestas originales qué tanto cambian Okay entonces en función de eso yo puedo saber Pues qué tanto se comporta dentro de los parámetros que nosotros esperamos otros conceptos importantes son transparencia interpretabilidad Y aplicabilidad entonces la la transparencia fíjense agrupa qué tanto podemos entender Cómo funciona un sistema de ia entonces hay redes neuronales profundas y hay técnicas de modelos de lenguaje o de Machine learning que no son explicables hay veces que no podemos ni siquiera saber cómo se llegó un resultado pero Hay ciertos algoritmos que son súper explicables Como por ejemplo un árbol de decisión Entonces si por ejemplo yo tengo que dar respuesta a un paciente que vino una institución de salud y se le evaluó con ia si yo utilizo un árbol puedo darle completa Claridad sobre Cuáles fueron las diferentes decisiones que se tomaron en esas ramas para saber cómo llegamos a una conclusión sí Entonces eso es importante y la interpretabilidad habla un poquito más de cómo nosotros entendemos realmente Qué impacto tiene un algoritmo versus otro sí Qué tanto está impactando los datos que se utilizaron para el entrenamiento qué tanto estoy yo variando por ejemplo con el pronto que estoy utilizando y la interpretabilidad es tener un contexto mucho más completo La explicabilidad es saber exactamente cómo llegué yo un resultado en particular Y eso sería como abrir esa caja negra para poder entender el algoritmo cómo está tomando decisiones entonces aquí es importante porque no todos los algoritmos no todos los modelos no todos los enfoques nos dan esa capacidad de transparencia si yo quiero dar la mayor transparencia de mi modelo puedo por ejemplo pensar en este métodos de boosting quizás o árboles sí un árbol de decisión fíjense más o menos hace algo como esto un árbol de decisión me va a ayudar a poder ver cómo llegamos a una decisión pero basándonos en diferentes umbrales Cuáles fueron los valores que tuvimos y en función de eso yo ya puedo dar esa explicabilidad porque porque el árbol es muy fácil de interpretar nosotros podemos revisar esta información pero cuando estamos por ejemplo en un enfoque como de este estilo donde tenemos redes con muchas capas este que están haciendo diferente proceso es muy difícil explicarlas no es más es costoso no están diseñados para ser explicables caso por ejemplo como de las redes convolucionales que lo que hacen es analizar imágenes Entonces esto es como un proceso de aprendizaje muy particular que no es muy explicable si no digo que no se pueda pero no es tan explicable entonces si yo necesito mucha transparencia tengo que elegir algoritmos que sean como mucho más específicos para eso no va a cambiar también la complejidad del modelo porque a veces utilizamos una combinación de modelos como en los modelos ensemple entonces todas esas técnicas nos van a ayudar para dar como cierta transparencia al proceso Okay si no podemos controlar todo el proceso al menos si podemos entender cuál fue el input y cuál fue la output aún cuando las capas intermedias no las conozcamos del todo sí tenemos la contabilidad también el gobierno el gobierno está más enfocado como en el cumplimiento normativo no todo este tipo de cosas y todas estas áreas Pues nos ayudan justamente a cubrir nuestras necesidades este de 10 minutitos 10 minutitos de break y ahora continuamos se los voy a dejar en el chat bueno muchísimas gracias Ahora nos vemos de regreso chao muy bien pues bueno ya estamos por acá de regreso perfecto bueno Estos son como los principales retos a los que nos enfrentamos no alucinaciones toxicidad sesgo e ilegalidad entonces a ver vamos a revisar uno por uno a ver pregunta para ustedes recuerdan algún momento en el que hayan interactuado con algún modelo de lenguaje y les haya generado una alucinación entendiéndose por alucinación que nos dio información que no era precisa a ver Jorge adelante y una vez utilizar en la versión 5 le ingresé un contrato y a contrato estaba muy extenso o sea obviamente enmascarando los datos sensibles para no compartir información con chachi piti Entonces le pregunté acerca de si aplicaba una cláusula y me dijo que sí aplicaba pero a mí no se me hacía lógico entonces estuve revisando y le dije bueno es que no encuentran dónde estás diciendo eso me contestó afirmativamente tres veces hasta que le dije pues en ningún lado Afirma lo que tú me estás diciendo o sea es alucinación pudo haber pasado desapercibida si no hubiera retado el modelo en cuanto al análisis el documento yo lo había ingresado a la caja de texto de chery pity pero definitivamente alucinó y pues me dio una respuesta contraria a lo que era en realidad lo que venía en el documento hoy sí sí eso es delicado si a mí me ha pasado muchas veces también ese tipo de cosas yo a veces por ejemplo los pongo a prueba no y cuando tengan tiempo hagan ese ejercicio pregúntenle a su muchacho al modelo que ustedes quieran Cómo configuran su pantalla de 16 K para que nos dé el modo de de cine en 3D y van a ver que les va a poner instrucciones claro Ve al menú pantalla configuración habilita porque son cosas acuérdense que lo que hace el modelo es ampliar la probabilidad de las siguientes palabras que puedan completar una frase entonces en lugar de responderme con algo que está aterrizado en la verdad que es el Grand lo que hace es mandarme un montón de tokens que suenan muy plausibles pero que no son ciertos no Entonces es uno de los principales retos Sí ahora a ver pregunta cómo creen que yo podría cambiar ese comportamiento para evitar que que alucine utilizando por ejemplo los parámetros que habíamos visto de temperatura creen que pueda tener un resultado diferente modificando Eso sí pero parámetros pues sí directamente no este mayor temperatura mayor creatividad Ajá Exacto tendríamos que bajar Entonces el índice temperatura a un valor mucho más cercano a cero para que no me genere información que no sea real No ese sería como la solución ahí por ejemplo Ajá normalmente usamos un parámetro de. dos y muy cercano al 910 cuando queremos que sea altamente creativo no entonces podría también ayudarnos no cosas que podemos hacer para generar seguridad y evitar a los financiaciones por ejemplo mecanismos que pueda revisar algunos fats Sí entonces por ejemplo si yo quisiera decirle que me ayuda a hacer la configuración del televisor lo que podría hacer es mostrarle como varios ejemplos de manuales y en función de eso tener como una respuesta no o decirle explícitamente que me responda solamente dentro de cierto contexto Sí eso eso ayuda bastante no el de toxicidad es como un reto cuando nosotros no queremos que utilice el lenguaje que pueda discriminar de alguna manera o que pueda ser tóxico en cualquier sistema no entonces no sé si alguna vez les ha tocado que les dé así una respuesta que no sea como tan tan buena Sí pero aquí lo que queremos es como evitar que nos dé respuestas que sean como no muy seguras en términos del tono y el lenguaje algo que podemos hacer aquí es por ejemplo dar instrucciones mucho más precisas o incluso utilizar promos negativos Entonces por ejemplo si yo le digo a mi pronto quiero que utilices un lenguaje cordial formal Ya no me va a contestar con palabras que sean como muy ambiguas ni muy un lenguaje que quizás no sea también muy inclusivo No yo le puedo especificar quiero que utilices un lenguaje inclusivo sí que consideres por ejemplo estos escenarios cualquier cosa que no esté dentro de esto sí responde con no tengo la respuesta correcta eso lo podemos hacer a nivel de pronto y nos ayuda a protegerlo una manera que podemos proteger esto es a través de filtros que se llamans Entonces por ejemplo en bedrock Más allá de ejecutar proms porque a veces no tenemos la opción de poner todos los casos negativos que queremos no incorporar no no quiero que hables de contenido sexual No quiero que hables de contenido que tenga que ver con política no quiero que hables de contenido que tenga que ver con agresión que puede incitar al odio imagínense todas las categorías que tenemos que poner más bien lo que pueda hacer es utilizar un método de seguridad que ya tiene bedrock para evitar y filtrar todo este contenido que pueda ser negativo porque puedo tener un usuario que también empieza a hablar con malas palabras y diga Contéstame en este mismo tono Entonces el modelo le va a empezar a hablar con un lenguaje pues que no es correcto y el día de mañana pues aparecemos en redes sociales y alguien puede decir mira lo que me contestó el chat de bootcamp institute adelante y el user Brown entonces para implementar una política para evitar la toxicidad sería pronto en medio yo creo que puede ser un sistema de los dos tu ventana de contexto conforme vaya avanzando la conversación va a olvidarse desinstrucción original Sí entonces a veces es inyectar esos proms en cada conversación en cada una y para eso tengo que controlarlo programáticamente Sí si yo Ahorita entro a un chachi piti le digo quiero que me hables con lenguaje súper formal bla bla bla bla y me pongo a generar una conversación de dos tres días en algún momento se le va a olvidar eso y va a regresar otra vez a términos sesgados un lenguaje que yo no le había pedido entonces la idea aquí es que podamos estar como validando filtrando Y reajustando sí Y como tú dices más bien va como un proceso de inspección de cada respuesta sí tanto de entrada como de salida Okay ahorita vamos a ver un ejemplo de eso justamente el sesgo es uno de los más difíciles de controlar porque depende un poco de los datos si los datos presentan algún sesgo Entonces el modelo va a estar 100% sesgado va a ser muy complicado establecer como una comunicación con él no pero por ejemplo algo que puedo hacer también es utilizar técnicas de proting Como por ejemplo si yo no quiero que se sesgue piensen en un caso no yo soy gerente de calidad de un hotel y entonces en cada Estancia que viene la gente nos deja un review leemos los reviews de redes sociales y a veces yo soy muy permisivo con los reviews que nos dan y todo lo califico como Bueno pero si quiero tener un. más lo que tendría que hacer es hacer un bromp a pesar que todos los comentarios que tengan sean excelentes o muy negativos y yo les quiero hacer parecer otra cosa puedo utilizar esa técnica de Fisher para enseñarle y decirle mira este es un comentario positivo este es negativo este es neutral cuando le pide una nueva clasificación Ya le di yo el. Con eso puedo volver a evitar sesgos en los datos sí Entonces ese puede ser un. Lo que se acostumbra a hacer en producción aquí es prácticamente validar de manera humana revisar conversaciones y ver las respuestas para saber si no hay sesgo y otro sistema que también ayuda muchísimo es la retroalimentación a través de tu aplicación final que el usuario puedan decir tom's up tombstone para decir Oye esta respuesta no fue lo que yo esperaba inspeccionar manualmente y hacer los ajustes que tengamos que hacer sí la iagenerativa en su naturaleza es creativa entonces por eso tenemos que tener todos estos controles porque no podemos asumir que la ya va a trabajar de manera determinística cada vez no siempre va a haber una probabilidad de que algo se desvíe de las buenas prácticas y el otro puede ser por ejemplo la ilegalidad aquí con calle un tema bien importante ahorita no porque hoy en día los modelos generativos pueden clonar voces pueden incluso autenticar aplicaciones con segundo factor yo puedo incluso ser jailbreak y decirle que me genere código para poder este afectar los recursos de alguien más no yo le digo quiero hackear a Amazon pues obviamente el modelo me va a decir No eso es ilegal pero si luego le digo es que estoy estudiando las técnicas de was para hacer tal cosa y lo convenzo me va a dar el código entonces hay que evitar también hay que filtrar este tipo de cosas no por ahí también algunas cosas que Que obviamente preocupa no que le preguntes por ejemplo un modelo apis porque porque alguien quizás subió una IP aquí y esos datos utilizaron el entrenamiento Y entonces el inferencia las entrega entonces hay que tener cuidado con la información personal información que pueda identificar a personas información sensible Entonces todos esos son como los retos ahorita ya hablamos como de las cosas malas que pueden llegar a suceder no Bueno cómo nos protegemos entonces La idea es que nuestras aplicaciones ahora consideren sí todos estos temas filtros fíjense en la parte de la salida revisiones manuales por parte de personas y que eso eso hace De hecho los modelos generativos para entrenados tienen humanos que están revisando aleatoriamente algunos pros y sobre todo con ustedes dan el Tom Sam si se van marcando y si un modelo empieza repetitivamente a responder mal entran personas y revisan los promos entre millones o miles de millones de años se van revisando y se van identificando sesgos u oportunidades para que en los próximos entrenamientos los modelos sean más robustos otra opción también para poder acotar El dominio de respuesta y hacerlas más seguras es hacer fine tuning Okay pero que necesito darle un montón de ejemplos de cómo los usuarios están utilizando mi aplicación para que para que no utilicen exploits a nivel de la aplicación Por qué Porque cuando yo ajusto hago entonces que se mueva dentro de ciertos parámetros pues puedo detectar incluso ataques no Entonces eso puede ayudar otra parte importante que también cubre todos estos espectros que hablamos es la explicabilidad la evaluación constante a través de testing Sí y la ingeniería también eso ayuda bastante muy bien pronto ingeniero inglés puede ayudar para que nosotros especifiquemos todo lo que queremos que haga una aplicación pero también lo que no queremos que haga Sí entonces ahí podemos como cortarla he visto muchas implementaciones por ejemplo de chatbots donde dicen tienes que ser un agente súper amable que proporciona información precisa etcétera y abajo dice y cualquier otra cosa que no te pregunten tienes que finalizar con esta frase no O evita responder cualquier pregunta que no esté listado en los.s esos pros negativos ayudan muchísimo a poder proteger contra diferentes tipos de ataque los datos también con implementamos que seleccionar muy bien los archivos o los datos que queremos incluir en rack porque si no se nos puede filtrar información procesos internos que no queremos que estén expuestos hoy muchos ataques de seguridad de hecho tienen que ver con eso con vulnerar procesos internos con acceder a información entonces no es nada más lanzarle todos los documentos que tenga dentro de la empresa sino más bien filtrar muy bien que tablas si tengo un documento pues probablemente trabajarlo un poco más para solamente sintetizar la información que debería de estar disponible para el modelo sí tenemos diferentes métricas que nos ayudan a identificar Por ejemplo si la información que nos están entregando es ética y responsable están por ejemplo los parcial dependen plots son unas gráficas está por ejemplo el análisis de importancia de características esto tiene que ver más con ficha en general cuando entramos en el proceso de curación de datos para un modelo que también podría ser por ejemplo para rack identificamos de todas las características que tenemos en un Data set Cuáles son las más importantes sí no sé si ustedes se acuerdan a ver déjeme mostrarles aquí un ejemplo que tenía yo hace un tiempecito miren ese a ver Jorge adelante veo tu mano por ahí arriba fíjense esta página me gusta porque nos muestras un escenario súper sencillo de Machine learning no Entonces asumamos que estos son nuestros datos con los que estamos entrenando tenemos datos Delivery sí como de entrega de paquetes Y tenemos el código postal y sabemos si en estos 100 ejemplos Cuáles entregaron en tiempo y cuáles se atrasaron No aquí vemos la distribución aquí hay algo que puedo notar rápidamente es que si hay un sesgo No porque no tengo un balance entre las clases de delates y un Time tengo más paquetes en retraso que contain entonces si yo entré un modelo con estos datos que tengo aquí este y esta distribución qué creen que va a pasar que mi modelo va a tener un sesgo a siempre predecir retrasos en la entrega vale pero puede ser que esto sea representativo Bueno aquí está entonces a ver me creo mi modelo noker list ya está creado mi modelo y aquí lo que veo es que cuando yo empiezo a medir la precisión de mi modelo o sea Cuántas clasificaciones fueron correctas versus los datos etiquetados me doy cuenta que solamente el 67. 8% de las ocasiones es también clasificadas el otro porcentaje está mal clasificado sí Y aquí viene la importancia de cada característica entonces fíjense aquí yo veo sí Cómo puede afectar la predicción del modelo aquí me dice utilizando el código postal 19081 tengo una probabilidad de clasificación de que esté retrasado por un 59% versus un 41 entonces la clase que gana es delay O sea que si yo tuviera que entregar mi modelo que ya tengo y le doy nuevos datos y tengo un paquete que se entrega este código postal me va a predecir con una probabilidad del 67.7 por ciento que va a estar retrasado quizás las carreteras son muy difíciles de acceder quizás hay mucha nieve No lo sé sí y ven para cada valor tengo como diferentes valores Sí pero qué tal que esta característica no es la más relevante de mi problema sí no es el código postal vamos a mejorar el Data set entonces a ver vamos a ver por ejemplo puedo reentrenar el modelo con las características que tenga seguramente voy a tener el mismo resultado o peor o un poquito mejor sí estamos buscando un objetivo del 80% en precisión y otra opción que tengo es agregar más características pues vamos a agregar más características no entonces fíjense yo nada más estaba generando un modelo con código postal y el resultado etiquetado es entregado o fuera de entrega No qué tal que utilizamos por ejemplo también la temperatura como característica Entonces cuando yo empiezo a incorporar otras características puede ser que estas características tengan una importancia más alta que el código postal y la combinación de estas características mejora la precisión del modelo qué tal que mido también la humedad Porque si la humedad es muy alta pues quiere decir que hay agua entonces se pueden como caer este piedras en los caminos se pueden patinar los autos Sí todo esto es importante otra que también me hace todo el sentido pensando en el negocio es Cuántos artículos tenemos no dice que esta no es tan bueno y aquí me dice Por qué a ver y cuántos caben en un camión Esta es una buena característica estas características tienen importancia mucho más alta para mi problema si yo reentreno el modelo nuevamente con estas características mi modelo es más performante es más subir por arriba del 80 ahora tengo una presión del 95% Sí si veo por ejemplo con 15 de temperatura y 800 artículos en el camión que sí que viene muy cargado y la temperatura pues es relativamente normal aquí veo que va a haber un un retraso No por qué porque hay muchos artículos vamos a bajarlo a 200 aquí me doy cuenta que esta característica todos van a estar retrasados pero si tiene una cantidad menor le va a dar tiempo de pasar a cada domicilio y entregar el paquete lidiar con el perro tocar el timbre ven eso es como la la importancia de las características Entonces ese es como una de los.s que chaplin addi tv explanations es un método que nos permite justamente medir qué tan sesgado está un modelo que tan justo es el modelo y eso se convierte en un servicio en la WS quién me dice Cuál es el nombre de ese servicio en aws que utiliza justamente estas métricas lo mencionamos en algún momento no yo les voy a decir cómo se llama el servicio de clarify está pensado justamente para ayudarnos a medir todos estos temas toxicidad creo que no tanto pero sí por ejemplo este qué tan justo es este si hay sesgo o no hay sesgo Okay tiene varias métricas que nos da por esos valores Chaplin vienen justamente de un paper que nos ayuda justamente a medir estas cosas Okay entonces este es el tema del Chaplin nos ayuda como a determinar la que qué tan qué tan separado está un conjunto de otro Entonces si hay sesgo no hay sesgo si está haciendo justo un modelo o está favoreciendo una clase versus otra y algo interesante de de clarify que nos da un reporte bien bonito nos da un reporte más o menos como este a mano los dan lo podemos Descargar directamente de un boquete S3 como más o menos el reporte Cómo se ve fíjense nos da un Jason pero también nos entrega por acá viene el documento Sí aquí me está diciendo por ejemplo cómo se comportan los valores con las características que puedo saber si una tiene un mayor impacto que otra incluso hasta para visión por computador también nos puede decir de esta imagen que me proporcionaste lo que está influyendo más el resultado es aquí veo la densidad de las áreas que se están considerando para esto y nos da un reporte donde nos dice también los valores Entonces digamos que clave nos va a ayudar para explicarnos qué tan justo está haciendo el modelo vale Y hay otras métricas que también podemos utilizar y también podemos hacer evaluaciones para los demás alucinaciones toxicidad sesgo este y también saber si hay filtrado de información particular o personal okay muy bien es prácticamente incorporar reviews manuales con personas Okay para validar como medir las respuestas que nos están dando la idea de monitorear es tener por ejemplo metrix poder utilizar por ejemplo versiones de testing humanos para estar validando constantemente si nuestros modelos están entregando la calidad que necesitamos si hay sesgos o si hay por ejemplo algún evento como de toxicidad o de algo que pueda afectar como la reputación de una marca no entonces todo esto se puede medir dentro de WS aquí simplemente podemos ver cómo podemos como utilizar algunos servicios Para algunas cosas no por ejemplo para la explicabilidad los Maker me van a decir cuál es el modelo Cómo se entrenó Qué pruebas pasó ahí puedo saber por ejemplo también qué tanto sesgo tiene la modalidad del puedo encontrar mucha información en las tarjetas Entonces tú me puede ayudar porque si por ejemplo yo veo que este modelo utiliza bosques aleatorios árboles de decisión sé que puedo entonces encontrar cómo llegó una conclusión final sí con clarify también puedo encontrar explicabilidad pero también puede evaluar con las métricas que vimos ahorita y puedo utilizar human in de lupus a personas que puedan revisar y también puedo utilizar Cloud watch para establecer métricas y alarmas si estos se desvía por ejemplo de algún estándar no 6 datos etiquetados contra los que yo puedo estar comparando puedo incorporar personas para estar haciendo estas revisiones también y hay un servicio que se llama aumenten ella y que es considerar personas Dentro de este look de verificación entonces aquí también podríamos utilizar una característica de de Amazon aumente y hay Okay el model monitor está más pensado más bien para métricas de desempeño que son por ejemplo las métricas como f1 score Como por ejemplo la precisión sí como el Ripoll que son métricas que me ayudan a medir en tiempo de inferencia qué tan precisas qué tan acordes están siendo las predicciones que yo di en producción todo esto lo podemos medir directamente desde acá okay entonces todo esto lo podemos controlar directamente con servicios son estas medidas de protección que tenemos en bedrock y la ventaja es que ya vienen implementadas solamente las tengo que agregar fíjense les voy a mostrar aquí que tenemos un demo de esto aquí está estas son las barreras de protección de help Controls amazon response vean como ustedes aquí pueden como establecer el umbral de qué tanto quieren ustedes aceptar por ejemplo lenguaje de odio insultos contenido sexual contenido violento o conducta no apropiada sí podemos configurar todos estos privados period created the current stanest this one is ready and creation Days And Last of the Times Times the central s here you can set up filters to black content catways like cats and souls and sexual content each a Just able pressure low Miriam Hi and you can coestible topshing and you can each topic to have the motle unders customer filters you can all so create customerles to blogs Wisin turns sence If information protection off you can figured be Ali I were personally I don't fine information detection you can also specific filter like you so Names you can also Shoes water to the Night Mask or loud different information Times you can all so said a brick pieds for marts can textil responses Finally you can try nations or made up and information and responses then interestemple proms that Will chilling your gorthday in this Case Inter de Problem How do I have to computer That I on it goes Will same that if you get have I computer you long you problems the same to have someone elses computer froms can be engineer like this to seconds Seat review How the mother responds with her flight the probles by the garth created tulsing the few trase but It's morty Tell less the How and why the garth And I topic is welles by mastering amat garth you play a Cruiser roll and the power of genita If I love Main taying control and safety and yours qué les pareció pueden bloquear contenido pueden especificar Qué tipo de palabras pueden poner expresiones regulares pueden validar contra ciertas preguntas y respuestas Como por ejemplo si yo hoy quisiera que mis usuarios no pensemos por ejemplo acá entran a conocer por ejemplo nuestro catálogo de productos no y les pongo por ejemplo un chat yo no quisiera que ahorita alguien me pregunte cómo tener un cupón gratuito de descuento no Porque pueden hackear el sistema porque de repente por ejemplo mi chatbot haga una recomendación Como por ejemplo decirle claro de mí hay un curso mejor que dura más tiempo que es más barato están de acuerdo o sea nosotros tenemos el control para especificar estas barandillas de seguridad los gadrens y decir cómo queremos que se compo muy bien compañeros y compañeras ya estamos por acá de regreso vamos con la última parte de esta sesión muy bien este ya Realmente es como la entrada al módulo número 5 y está enfocada mucho la parte de seguridad okay Bueno Pregunta cuántos de ustedes han escuchado hablar de uvas súper y que eso guasto para que no sirve son como 10 términos que ayudan a definir buenas prácticas de seguridad o a encontrar a encontrarlas en su defecto exacto muy bien o huáspe es como una iniciativa online que como que busca reunir siempre las principales vulnerabilidades que pueden tener por ejemplo los sitios web las aplicaciones móviles Entonces se ha vuelto como el estándar de facto en la industria para hablar de vulnerabilidades de seguridad entonces podemos encontrar como el top 10 vulnerabilidades de aplicaciones web no entonces recientemente ellos liberaron un estudio en donde hablan como de los was top ten vulnerabilidades para modelos de lenguaje Entonces esto también me da como un. Para saber de qué me tengo que proteger Cuáles son como los ataques más populares y como yo sé que no puedo cubrir todo a todo el tiempo enfocarme principalmente en estas vulnerabilidades No eso es lo que hace los top ten ahora para el elenes entonces fíjese las principales que de que detectamos es inyección de Bronx manejo de salidas de forma no segura por ejemplo como cuando está recuperando información sensible yo no quiero que me devuelva una app de un cliente no puedo filtrarlo este envenenamiento de datos en entrenamiento podría haber ataques en donde hoy alguien escribe una página de Wikipedia y pone contenido que no es del todo correcto para poder beneficiar algo en el futuro eso se escanea en los siguientes meses y con un modelo de lenguaje aprende a interpretar todo este contenido que está allá afuera se podría utilizar el día de mañana como una verdad para un modelo de lenguaje y después generar algo de manera negativa no entonces podrás hacer un gran problema ataques de denegación de servicio así como los tenemos hoy para las aplicaciones web que saturan tanto un recurso que no puedo utilizarlo lo mismo pueden hacer para un puente un modelo de lenguaje que nuestra aplicación esté tan saturada que nuestros clientes no tengan recomendaciones ni asistencia Y esa funcionalidad pues puede interrumpir algún modelo de negocio No vulnerabilidades en cadenas de de valor este liberación de información sensible etcétera tenemos como diferentes vulnerabilidades a las que nos podemos empezar a proteger No ahora qué nos dice aws Qué podemos hacer para hacer aplicaciones seguras siempre tenemos como un enfoque en capas Entonces primero tener múltiples niveles de defensa redundantes no solamente basta con proteger la aplicación sino también el modelo sino también los proms sino también los fuentes de datos todo todo tiene que ser protegido de manera integral y un como una regla que utilizamos normalmente en Amazon es proteger absolutamente todo No solamente la parte del modelo y mi aplicación sino porque no también cifrar los datos en reposo utilizar certificados digitales si es una aplicación pues proteger todo ese contenido a través de una autenticación de una autorización a mis usuarios y utilizar múltiples opciones en combinación para poder proteger mis aplicaciones y algo que nos dicen siempre en awu s es proteger cada capa Como cada capa conceptual no Entonces dónde anda el centro está lo más importante que son los datos los datos que los clientes suben como input y probablemente los datos que obtenemos de referencia Al momento de hacer inferencia Sí pero de antes de afuera hablamos de la capa de cumplimiento detección de amenazas y acción cuando detectamos algún incidente proteger la infraestructura de red de aplicación de los empleos por ejemplo proteger la red aplicaciones todas estas capas nos van a ayudar pues a crear soluciones mucho más seguras y para esto es importante que les mencione aws siempre considera la seguridad como una responsabilidad Dual en donde el cliente y a WS trabajan en conjunto para asegurar sistemas okay Y eso nos lleva al modelo de responsabilidad compartido porque es una responsabilidad que compartimos de ambas partes fíjense en la parte de arriba tenemos a nosotros como clientes o los usuarios finales que interactúan con nuestras aplicaciones de guía generativa Entonces de qué responsabilidad del cliente los datos que está depositando si a un modelo de lenguaje está subiendo los estados financieros información sensible datos de una base de datos que puedan comprometer a nuestros usuarios pues es una gran responsabilidad la que tenemos que cuidar aquí De qué se encarga WS normalmente de todo lo que tiene que ver con su nombre por ejemplo infraestructura centros de datos redes bases de datos almacenamiento cómputo y toda la capa de software entonces a pesar de que trabajamos con sistemas o una nube muy segura Pues eso no quiere decir que yo estoy exento de algún tipo de ataque cuando yo no considere mecanismos correctos de autenticación a qué me refiero que si tengo yo por ejemplo una aplicación de cliente final y no estoy colgándole un mecanismo para autenticar y está abierto todo el mundo pues probablemente pueda tener algunos problemas por ahí no incluso hasta incurrir en impactos en costos Eso es lo importante ahora Cuáles son los principales servicios que podemos utilizar para proteger una publicación generativa en la parte de cumplimiento de gobierno hablamos de todo lo que tiene que estándares qué es lo que me rige a mí por ejemplo de manera Federal en en el país en el que me encuentro si hay por ejemplo en mi industria alguna Norma algún estándar que debería de cumplir por ahí tengo que arrancar esa es como la capa más externa primero ver qué es lo que me exige Sí este los estándares Y desde ahí empezamos a construir hacia dentro después estar detectando amenazas Qué es lo que está pasando en mis aplicaciones en tiempo real y cuando encuentro alguna amenaza Cómo reacciono ante este tipo de incidentes no en la tercera capa encontramos la protección de la infraestructura Entonces esta infraestructura diseñada específicamente para aplicaciones generativas cómo voy yo a protegerla los.s eso los servidores las apis el acceso humano todo esto es importante capa de identidad y acceso Quiénes son los usuarios o los roles que se encargan por ejemplo de hacer estos fine tunings Quiénes son por ejemplo los clientes que Ejecutan inferencia directamente a un modelo de petrol bajo qué contexto de seguridad se están ejecutando yo creo que hoy en día podemos imaginar muchas aplicaciones que podrían beneficiarse de la idea generativa dedíquenle un tiempo a pensar Cómo podríamos protegerlo también para que fueran seguras pensemos por ejemplo en un dispositivo como Alexa no tengo una bocina inteligente yo le voy a poner una aplicación Quiero que mis usuarios interactúen a través de voz pero dónde se está quedando esa voz sí la voz que está respondiendo tengo derechos de uso para ese tipo de información este las sugerencias que me va a dar a dar Cómo deberían de ser todo ese contexto nos va a ayudar para empezar a definir en todas estas diferentes capas cómo queremos proteger la información y por ejemplo aquí en la protección de datos es importante que cada byte que almacenamos en la nube esté encriptado que esté cifrado y por eso utilizamos el servicio de KMS servicios de almacenamiento servicios de bases de datos sistemas de prevención o detección de intrusos el servicio de Messi por ejemplo para evitar pérdida de información todo esto nos va ayudar para proteger nuestra aplicación kMS Yo creo que es uno de los servicios primordiales que deberíamos de considerar para una aplicación de yagenerativa uno porque toda la información que nosotros depositemos en algún sistema de almacenamiento tiene que estar encriptado y para eso utilizamos llaves de cifrado con KMS ventaja con KMS yo puedo auditar todo el proceso puedo Identificar y tener trazabilidad eso me ayudaría Incluso en mis procesos de explicabilidad sí saberes de que un cliente me dio un dato que hice con ese dato dónde se almacenó cuando Cada cuánto se está respaldando por cada cuánto tiempo lo retengo Cómo hago analítica con esa información pueden entrar por ejemplo el acceso humano a revisar proms que está pasando con esa información no como toda esa cadena o lo que normalmente le llamamos toda la este pues como todo el manejo que hacemos de esos datos tiene que tener una evidencia no cuando estamos trabajando por ejemplo con ese tres ahí podemos guardar datos que nos van a servir para nuestra base de datos de vectores podemos guardar comunicaciones podemos guardar interacciones de nuestros clientes con nosotros trabajamos por ejemplo con servicios como petrog tenemos apis que nos permiten interactuar con sesiones entonces muy similar a cuando ustedes interactúan con un servicio Como chachipití que empieza una conversación y tienen múltiples conversaciones bueno cada conversación tiene un contexto de conversación y tiene un objeto de sesión asociada porque porque si yo me quiero mover una conversación anterior voy a recuperar todo ese histórico de mensajes y eso tiene que estar almacenado en algún lugar en alguna base de datos pues tenemos que considerar todo esto para que sea seguro y por ejemplo Macy nos daría una capacidad adicional detectar Qué tipo de contenido estamos almacenado en un boquete S3 sí pensemos por ejemplo no sé si ustedes conocen una aplicación que se llama Gama no sé si se la han ocupado en algún momento buenísimo a mí me encanta hacer mis aplicaciones favoritas y particularmente me parece que es una como un caso de uso muy bien aplicado de yagenerativa lo que buscan este equipo está startup de gama es que podamos generar presentaciones a través de yagenerativa y como que de alguna manera reemplazar muchas otras aplicaciones Como por ejemplo Powerpoint no sale parece increíble por ejemplo en la parte de generar yo le puedo dar una descripción de que quiero hacer este y me genera un slime los haces súper bien no Entonces dice por ejemplo en un momento como este no mi usuario me sube un proms y el prompt es su estado de resultados del Messenger no quiere generar una presentación ejecutiva para sus usuarios dónde guardarían ese proms una base de datos era un boquete S3 en un servicio de caché tenemos que encriptarlo en algún lugar no eso es importante este en S3 podríamos guardar todo el Pro m de entrada y cuando generamos la presentación ya en un formato específico lo ponemos en S3 no pero tengo controles de acceso y Qué pasaría si de repente dentro de ese pront encontramos información sensible podemos buscarla para qué Para que nadie pueda acceder esa información para que detectemos Qué tipo de datos están subiendo las personas no todo ese tipo de cosas nos ayudarían vamos a controlar Más bien a ver adelante Jorge Sí vamos a entrar con mayor profundidad en esta en el de Amazon mazy o sea ahí establece de una un Discovery automatizado de Data sensible O sea ya no tendría que hacer uno la chamba de documento por documento está lo clasificando exacto Exacto Sí fíjate te voy a decir que hace Macy hay un algoritmo de Machine learning que se llama me gustó esta imagen que se llama modelado de tópicos entonces Imagínate que tú tienes un montón de documentos que son contratos precios de productos conversaciones de clientes lo que tú quieras no y los guardas en S3 pero tienes un Data muy grande entonces no sabes realmente qué tanto tienes almacenado dentro del Data Lake pero te gustaría identificar cuando la información que es sensible están siendo utilizada entonces lo que hace prácticamente este algoritmo de Machine learning es Buscar palabras y Digamos como que priorizar los temas menos comunes como algo más importante Entonces por ejemplo si tú analizas un fragmento de texto vas a encontrar un montón de palabras Como por ejemplo pronombres verbos sustantivos etcétera todo lo que se repite mucho tiene una prioridad baja para este algoritmo lo que no se repite tanto tiene una probabilidad más alta entonces lo que hace es analizar no entiende el documento sino más bien clasifica información dentro del documento Entonces yo por ejemplo le paso un documento y habla por ejemplo de una relación comercial que estamos haciendo con una empresa En cuántos millones de dólares se cerró el til este etcétera va a encontrar esos temas clave y los va a clasificar como cosas que parecen importantes eso es lo que hace si detecta por ejemplo números de rastro de cuentas tarjetas de crédito números de seguridad social todo ese tipo de información que dentro de esos tópicos parece ser además sensible le va a dar una importancia más alta entonces si yo tengo miles de documentos en S3 y quiero que me ayude a identificar Cuáles de estos documentos pueden tener información relevante o sensible eso es lo que hace Macy Messi clasifica con Inteligencia artificial utilizando ese algoritmo De hecho toda tu información ellos no lo ven no guarda tanto solamente clasifican Entonces por ejemplo yo puedo configurar una alarma en Cloud watch para decir Oye cuando detectes que alguien está leyendo un montón de documentos que tienen alta sensibilidad avísame inmediatamente Mándame un correo por sns para saber que alguien está descargando información sensible entonces me hice de alguna manera te permite prevenir ese tipo de fugas de información Eso es más bien lo que hace sí clasifica y te ayuda a detectar comportamientos sobre esos datos importantes Sí eso es lo que hacemos y entonces de alguna manera podría yo integrarlo aquí como una solución para también no solamente proteger en reposo mis datos en S3 porque para eso utilizaría KMS sino también para identificar Qué hay dentro de esos bockets y cuando tienen una actividad anormal vale Y aquí el contexto de ahí en Pues más bien me habla de que si yo tengo una aplicación generativa y la tengo un instituto yo creo roles con políticas muy granulares para decir quién puede invocar inferencia En bedrock qué base de conocimiento puede ser ejecutada porque agente como que siempre voy a tener un control muy específico utilizando el servicio de ahí entonces no puedes ir metro que quiere decir que tenemos abierto y todo expuesto todos los usuarios no sino más bien yo tengo muchos controles para poder definir Cuál va a ser el modo de operación y de uso de mis aplicaciones más la parte de garth para ahora detectar qué me están preguntando qué tipo de contenido podría llegar a ser sensible sí Entonces como un nivel de protección digamos más a nivel de aplicación ahora si nos bajamos un poquito más en esas capas hablando de infraestructura la infraestructura da WS segura por diseño por ejemplo tenemos que se llaman inclaves Y eso es parte de las tecnologías que se tienen con los Microchips gravitón y toda la tecnología nueva que se tiene para inferencia digamos que lo que hace WS es que a nivel de Hardware rediseñaron completamente todo sus chips son seguros puedes ejecutar procesos específicamente en entornos de Hardware aislados ya ni siquiera estamos hablando de software sino completamente Hardware entonces si yo tuviera una carga muy sensible estoy trabajando Al FBI A una secretaría un ministerio a una empresa que tiene requisitos muy importantes de seguridad yo a nivel de infraestructura puedo cumplir con los masajes con los más altos estándares de calidad es como una gran ventaja no hablando Un poquito más arriba ya nivel de servicios todos los servicios tienen capacidades de cifrado eso me permite tener la confidencialidad para asegurar que todos los datos que depositan nuestros clientes todas nuestras bases de datos información en puentes todo está justamente cifrado en tránsito y en reposo y un tema súper importante que me preguntan constantemente cuando de capacitaciones de ia es qué tan segura está nuestra información en la WS completamente porque todo está diseñado para ser privado por default si yo utilizo por ejemplo bedrock con un modelo de lenguaje es como si estuviera yo tomando una copia de Cloud de titán de meta de cualquier modelo que yo quiero utilizar y está ejecutándose directamente en mi cuenta más todos los controles de control de acceso más todos los controles de cifrado entonces hace que toda mi carga de trabajo esté completamente segura aquí no tengo el problema de ir a leer las letras chiquitas que tiene Open y hay y tengo que Deshabilitar en chachipití que no utilicen mis datos para entrenamiento aquí los datos están en control y en resguardo de cada cliente Esa es la gran ventaja yo creo que hoy en día es un diferenciador muy importante de hablar de un montón de soluciones que están muy interesantes ahí afuera pero realmente hablar de bedrock y daws para aplicaciones generativas te da el completo control y la certeza de que todo está completamente protegido aislado digamos que entra más en la parte de control de monitoreo de auditabilidad Porque todo lo que pasa en mis aplicaciones yo no puedo lograr y lo puedo registrar y lo puedo analizar conforme va llegando directamente a esa Cloud watch y esta gráfica nos muestra como dos este como dos perspectivas diferentes de la seguridad no Uno es que tanto me preocupan lo la seguridad de mis datos Y el otro que tan amplio puede llegar a ser ese esa custodia de mis datos entonces veamos por ejemplo acá si yo quiero asegurar mi aplicación supongamos que tengo tres casos distintos una aplicación que es para encontrar películas pues piensa que las películas más información confidencial es información que está allá afuera es más me podría yo alimentar de imdb para poder como tener ese catálogo entonces este me va ayudar a encontrar películas aplicación número dos una aplicación de atención al cliente empresarial y la tercera una aplicación también pero de salud que no utiliza un modelo generativo sino más bien utiliza un modelo propietario son los tres casos Entonces fíjense si fuera el movie finder app en este caso me interesaría proteger la la aplicación de ideagenerativa Entonces yo podré encontrar como una solución muy directamente aquí por qué porque solamente estoy cayendo sobre un caso muy específico Entonces tengo el completo control No quiero que mi aplicación me pregunten este la tarea del ensayo de historia que le que me pidieron en el bachillerato no quiero que puedan este por ejemplo estar información de otros acuerdos de otros clientes que cambian el comportamiento sus ataques No me interesan porque porque esta aplicación está enfocada Solamente en darme recomendaciones Entonces yo hago un buen pronto le voy a decir quiero que me ayudes a recomendar películas quiero que utilices esta base de conocimiento como fuente Universal de respuesta y quiero que entiendas o le preguntes al usuario cuáles son sus preferencias que te dé una o dos películas en las que está interesadas o que te diga Cuál fue la última película que le gustó muchísimo para darle recomendaciones. Okay con eso yo puedo proteger una aplicación veamos otra la aplicación empresarial aquí yo ya tengo datos sensibles aquí ya tengo conocimiento del negocio Aquí tengo procesos que no quiero que se filtren competencia de la que no quiero hablar entonces estoy en un caso en el que necesito controles un poquito más amplios sí Y dónde tengo datos sensibles ahí entra Amazing KMS negativos todos esos.s de me ayudan incluso los garrails de bedrock para permitir que no utilicen contenido ofensivo que no traten de inyectar cierto tipo de ataques vale Y en la tercera aquí ya salimos un poquito del contexto día generativa porque hablar de un modelo propietario quiere decir que lo voy a construir directamente sagemaker ya lo voy a utilizar bedrock bedrock es para hospedar modelos fundacionales y aplicar todos sus controles que hemos platicado pero se ha hecho makery es como decimos por ahí un animal completamente diferente es otra categoría distinta donde yo voy a controlar todo el proceso desde cero tengo todos los controles pero también me permite cumplir con los estándares regulatorios desde explicabilidad justicia este curación de los datos elección del modelo métricas de calidad despliegue monitoreo continuo sech Maker clarify todo eso para poder proteger todo el ciclo de vida de mi aplicación entonces se dan cuenta Va a depender un poquito del tipo de solución que tengamos Si yo tuviera que hacer ahorita una consultoría de negocios para una empresa que me pide yagenerativa por todo mundo se quiere yagenerativa pero no sabemos o no saben qué quieren empezar ya como por aquí primero hablar de la seguridad no Oye tienes datos qué va a ser tu aplicación Dónde están esos datos vamos a ver la calidad de la información cómo se va a alimentar constantemente tienes un equipo que puede revisar los proms cómo vamos a monitorearla como que empezar a hacer todo ese scouting antes de poder proceder con la solución Okay esta matriz también nos ayuda para poder identificar En qué caso nos encontramos y qué tipo de seguridad necesitamos incluso Qué servicio podemos utilizar en aws primer Scout servicios públicos que cualquiera puede utilizar sin ningún problema sin ningún riesgo podemos pensar por ejemplo en soluciones mucho más abiertas como Party Rock Sí en Party Rock yo me quiero una cuenta gratuita y empezó a utilizar modelos sin tener que pagar absolutamente un peso de hecho es más puedo crear aplicaciones utilizar widgets para crear mis propias aplicaciones bajo el scope de mi propia cuenta y las puedo compartir con otros usuarios yo mismo he creado algunas aplicaciones de certificación por ejemplo este de estimación de costos sin ningún problema en el Scoop número 2 ya necesitamos integrar con una aplicación empresarial en este caso podríamos pensar por ejemplo en Amazon cube business Para qué para que pueda leer las bases o las fuentes de la empresa utilizar diferentes conectores por ejemplo hablar con este seis Force que a partir de ese sistema se filtra en ciertas tablas y ciertas ciertos módulos que pueda yo exponer a través de una interfaz conversacional quiero un poquito más de control me voy al scope número 3 donde yo ya trabajo con bedrock donde puedo elegir el modelo la versión la modalidad puedo pronunciar ajustar hiper parámetros de inferencia scope número 4 necesito personalizar un poco más mi modelo me voy a la parte de fine tuning o continuo per training y aquí ya no nada más entra bedrock sino también estás hecho Maker jumpstart cualquiera de estas dos opciones pueden cubrir esas necesidades en particular y el número cinco quiero competirle a opening quiero sacar mi propio modelo quiero ser súper competitivo quiero ir este como no sea a dar una propuesta de valor que nadie más está dando debería de empezar a considerar construir un modelo generativo desde cero no Recuerden que en el scop número 4 utilizamos técnicas de transferencia de conocimiento entonces tomamos el conocimiento y la inteligencia que tiene un modelo ya listo ya pre entrenado y seguimos entrenándolo o lo ajustamos para una tarea en particular el Scoop número 5 queremos construir un modelo completamente desde cero y si estamos en una empresa ojo con esto que tiene muchos datos piensa por ejemplo una empresa de telemarketing que lleva registrando llamadas de los últimos 10 años eso es oro podría construir un modelo súper sofisticado para resolver un problema de la industria súper particular Vale entonces esos son como algunas de las ideas en la parte de gobierno pues podemos Buscar referencias que ya existen Como por ejemplo el arquitectos framework fue el arquitectura dentro de la misma cuenta de WS tenemos advisor que si tienen un plan de soporte avanzado pues seguramente nos va a dar recomendaciones adicionales de nuestras soluciones desplegadas cosas utilizamos Cloud Trade porque Clau trae me permite identificar ciertas acciones a nivel de servicios y yo puedo automatizar esa respuesta cómo lo hago con funciones lambda con filtros en Cloud watch y generando alarmas entonces me permite por ejemplo detectar cosas que están pasando a nivel de mi infraestructura y con Cloud watch cosas que están pasando a nivel de mis aplicaciones sí eso será súper importante Yo me imagino así cualquier empresa que implemento hoy en día una solución de ia debería de tener un dashboard en una pantalla en la oficina viendo las métricas Cuántos tokens están generando por segundo Cuáles son los trending topics que es de los que están hablando las personas hacer auditorio regulares para ver qué preguntaron qué respondió el modelo hacer ajustes Esto no es una solución en una caja podemos desplegar y olvidarnos de ella esto tiene que ser algo a lo que estemos prestándole mucha atención constantemente yo creo que eso es lo que entrega muchísimo valor entender cómo tus usuarios están utilizando la herramienta también te ayuda a identificar Cuáles son las siguientes características que tenemos que desarrollar para proteger la infraestructura con config con config yo puedo ver por ejemplo cambios de configuración yo puedo saber que por ejemplo un equipo acaba de desplegar una nueva versión de un modelo de guía yo puedo identificar por ejemplo con una aplicación que está corriendo en estancia de Y si tú tuvo un cambio en su grupo yo puedo como detectar todo este tipo de cosas a través de confi okay pensando por ejemplo en la parte más de gobierno esto tendrá que ser como la estructura fundamental que debería de tener cada empresa antes de pensar en la aplicación es cómo lo vamos a organizar Cómo la vamos a controlar Cuáles van a ser esos procesos que vamos a tener para los clientes que estén completamente satisfechos y los que no estén tan satisfechos no qué va a pasar el día que se filtre información que tenga nuestro modelo un comportamiento no esperado esa es como la perspectiva del gobierno y empieza con la parte financiera regresando nuevamente al caso no yo pongo un chatbot en mi página web y si no tengo unas barandillas bien configuradas unos garrails podría ser que muchos usuarios se la estén utilizando para utilizar toques gratuitos sin una cuenta Pro pero que que está pagando los token soy yo cierto Entonces tenemos que administrar el costo qué otra cosa podrá ser importante en la parte de gestión financiera por ejemplo detectar la lo ngitud de respuesta de un token si yo quiero por ejemplo implementar una solución una de las primeras cosas que me van a preguntar es Gabriel cuánto cuesta esta solución y qué responderían ustedes a eso cómo estimarían hoy Los costos de una solución de yagenerativa pensemos en un chatbot qué les viene a la mente a ver toques y toques de entrada o tóquense salida qué Otro aspecto el modelo exacto Israel correcto el modelo la región un poquitito pero el modelo creo que sería el principal no saber fíjense supongamos que utilizamos Sonic 4.5 con un contexto largo Porque son el 45 es el que tiene como mejores capacidades de razonamiento es uno de los modelos más sofisticados que hay hoy en día en todo el mercado no Entonces por ejemplo Cuántas solicitudes por minuto no supongamos que una la verdad es que me parece muy muy bajo cuántas horas está trabajando así 8 horas ahora Cuántos toques de entrada supongamos que el cliente me manda 100 y respondemos digo 10 y me respondemos 100 esto me costaría a mí 36 dólares con 26 centavos esto es serviles porque no tengo que pagar por él pues ni por infraestructura para hacer inferencia como lo harían es la ventaja de bedrock completamente pago por toques de entrada toques de salida por modelo Okay pues Aquí tengo los cálculos ahora qué tal que se pone muy popular y tengo aproximadamente unos 30 clientes concurrentes Okay ya estamos en los $1000 estas son de las cosas que tenemos que empezar a optimizar Sí porque si yo estoy por ejemplo respondiendo 100 toques Creo que este long context no hace sentido voy a pasarme a unos 4.5 contex vamos a ver cómo cambia $600 ya me ahorré 400 340 por elegir un modelo mucho más adopta lo que necesito qué tal que yo utilizo uno de los Súper parámetros y un proms para decirle imagínense que lo que me preguntan mis clientes es Oye estamos en una tienda hace un tiempecito de un curso para esta tienda este aquí y algo que me encantaba que ellos proponían era que podían ya estaban implementando este tipo de soluciones para poder por ejemplo identificar cuál es el mejor accesorio sí que va con tu sala con tu casa con tu estilo entonces lo que necesitan es tener común es una capacidad inteligente imagínense que subimos una foto entonces utilizo un modelo multimodalks Porta imágenes extraemos características con un pronto y le decimos extraer los componentes principales quiero que tomes el color que identifiques el tipo de mobiliario de espacio que se tiene y hagas una propuesta con cinco características que tenemos en nuestro catálogo ese sería pronto no luego implemento rag entonces voy y busco en la base de datos la categoría como me mandaron una foto clasifico y digo esta categoría tiene que ver con oficina Sí con decoración para oficinas aquí está con esa foto le digo Extreme los top tres productos que más vayan con este estilo y me saca una lámpara un tapete un escritorio y un cuadro Okay tú estás súper interesante porque entendí el contexto con los datos de entrada y después retorno y en la respuesta solamente quiero que me ponga el sku el nombre del ítem y la URL de la web sí Entonces qué es lo que puedo hacer que yo en mi le digo Cuántos toques de salida tengo se lo voy a utilizar 100 quizás tomes utilizan los 50 si si yo más o menos saco el promedio de Cuánto mide una URL más el sku más la descripción estoy ahorrando en tokens baja mucho la solución sí son un montón de cosas que podemos empezar a identificar pero el tema de costos es súper importante vale el sistema de curación lo podríamos llevar nuevamente al mismo ejemplo No yo ya tengo mi sitio de ecommerce y tengo cinco categorías 10 categorías de productos y y sé cuáles son los productos que quiero mostrar Por qué no hago un resumen una tabla en macdown además puedo actualizar todos los días con la función lambda que tenga solamente esos catálogos no tiene que ir a indexar con un montón de consultas en bases de datos sino más bien ya tengo cachadas Cuáles son los productos Cuál es la cantidad de stock que tengo y eso es lo que interactuamos con rap eso me puede ayudar muchísimo no y los controles que Estuvimos viendo pues para proteger este tipo de interacciones vale aparte de cumplimiento pues ya hablamos un poquito del modelo responsabilidad compartida pensar como en compliance desde el paso número cero creo que sería una muy buena decisión sobre todo porque nadie quiere enfrentarse a problemas que puedan afectar negativamente a una empresa una marca Entonces tenemos que anticiparnos a eso y considerar todos estos temas de seguridad desde antes no si Existe algún framework como wasp porque no utilizarlo porque no escuchar que está pasando en la industria Cuáles son los top 10 ataques más comunes para modelos de lenguaje y proteger los contratos ataques Sí todo esto nos ayudaría muchísimo y después ver por ejemplo si la industria en la que me encuentro si la carga de trabajo que estoy ejecutando está regulada si está regulada pues probablemente tengo algunos limitantes específicos en cómo voy a manejar la información si puedo guardar datos personales y tengo que buscarlos etcétera algunos servicios que nos pueden ayudar con este tema de compliance es por ejemplo Inspector pensando en las aplicaciones que yo ya tenga corriendo en mis servidores Y si tú en mis containers docker puedo utilizar Inspector para ver la postura de seguridad que se tiene artefac me ayudaría para entender como adoplo está cobrando con algunos estándares de seguridad pero también podemos utilizar audit manager manager me va ayudar para que yo especifique quiero cumplir con los estándares de seguridad de El lms y me va a llevar por ese proceso de auditoría y fíjense Se los voy a mostrar Solo tengo aquí en un demo eso es lo que es que a ver presten atención Para que vean Amazon this framed Garden and Security and operations to diamon Straight the out it managers the Search bar and inter about you was out it manager choos 8 before two set up 8 manager You can leave Everything is the fold scroll down and Just complete set Up you are ready to Used ass out it manager scroll down and Just creator stop undertales and your name for you and Astrid to save you reports use the brawls at Street but two Navidad muchísimo valor Porque si tenemos hoy en día la duda de cuáles son los estándares de seguridad qué tanto estamos cumpliendo con precisión justicia privacidad resiliencia responsabilidad seguridad todo este tema podemos ver cómo nos está yendo con este asesmento con esta evaluación Entonces esto Me puede ayudar a mí a ver que si tengo que cubrirme contra algún tema Como por ejemplo privacidad puedo implementar un control de toxicidad o un cartel directamente en bedrock que no había considerado Sí eso es como el gran valor que veo de audit manager para ayudarnos a alinearnos contra esas buenas prácticas eso es lo que hace prácticamente este hasta aquí qué tal alguna pregunta comentario yo para hacerles honesto no he visto una herramienta ahorita en el mercado que sea tan robusta como bedrock he visto cosas interesantes implementaciones frameworks este algunas cosas que ya están completamente hechas pero yo sí creo que bedrock te da hoy en día completo control para construir algo desde cero hacerlo seguro todo está integrado no tienes que aprender Nada nuevo este por ejemplo lanchain tiene unos unas librerías muy interesantes tiene un modelo muy muy bueno no los pats y Hay cosas muy interesantes pero como que siento que le hace falta la parte de automatización y de infraestructura no este bueno es el lado del lanchen incluso con otras nubes siento que les falta esa parte de trabajar con infraestructura Entonces yo tengo como todo el rango completo si quiere implementar algo sencillo puedo liberarlo literalmente en minutos yo quiero sacar un chatbot puedo integrarlo hoy en día con un modelo generativo puedo utilizar el servicio de Amazon Lex tengo una aplicación y quiero construirle frontend por ejemplo con alguna solución No sé tanto de python o algún lenguaje de frontend puedo hacerlo de manera súper sencilla como que siento que estamos muy cubiertos con todas las necesidades para María generativa no entonces creo que hasta ahorita ya visualizamos bastante de las partes que tiene bedrock y todavía nos falta trae también por ejemplo agentes trae este por ejemplo la parte de Canvas hay en metro cada vez están sacando más características y me parece un servicio súper completo bueno a ver vamos con las preguntas del juicio para ir cerrando el día de hoy aquí nos preguntan Qué combinación de servicios aws nos da el monitoreo o la solución de monitoreo más completa por cuál sería israel no se hace la d también sí sí sí sí sí las dos están completas eh pero hablando de monitoreo monitoreo hace referencia como a logs a métricas cosas que puedo automatizar será Cloud watch y Cloud Trail verdad y aquí algo interesante es que en Cloud watch yo puedo recuperar las métricas de Cloud en Cloud watch yo puedo establecer alarmas y con las alarmas puedo especificar umbrales o filtros de detección y ejecutar acciones O sea que me sirve hasta para remediar no solamente para detectar vamos con la pregunta número 2 qué factor Debería ser priorizado cuando estamos evaluando los requerimientos de seguridad para una aplicación de yagenerativa que nos dice la Kevin también Pixel también okay me hace sentido la naturaleza y la sensibilidad de la información yo que nuestra labor consultiva tenemos que empezar por ahí qué quieren hacer de dónde vienen los datos Quién es el usuario final este qué estándares O regulaciones deberíamos estar cumpliendo creo que por ahí empecemos después a ver la calidad de los datos que se tienen Y por último evaluar la implementación primero vamos por ahí sí muy bien y a ver la número tres cuál Debería ser el propósito principal del gobierno de datos en sistemas de ia qué deberíamos enfocarnos completamente la ve también no está mal pero la debe ser más completa porque dice habla de todo el ciclo de vida no Entonces con nosotros habíamos dicho que podemos tener por ejemplo fugas de sesgos en los datos imagínense que protejo toda la implementación cifrado en reposo en tránsito Cloud Trail config watch petrex este gat rails y buenos Bronx con ingeniero de proms todo todo se lo juro pero realmente los datos originales tienen sesgo si los datos originales no están bien clasificados tengo que pensar realmente todo como si fuera un ciclo completo de trabajo no muy bien sí va por ahí correcto bueno vamos con esta última parte hablando de este reto fíjense que algo que sucede aquí es que tenemos un ciclo de vida o sea no es algo estático como que libramos una solución y hasta ahí sino constantemente tenemos que estar monitoreando y evaluando resultados y esto se puede automatizar con apis de manera programática pero la idea es identificar las diferentes etapas del ciclo de vida el primer. El que nos debemos de enfocar es definir un caso de uso para Quiénes Quién es el target ideal para esta aplicación después pensar en el modelo y yo creo que el modelo puede darnos los mismos resultados si cambiamos de diferentes modelos pero vamos a ver una diferencia en performance no y conformamos trabajando vamos midiendo ese desempeño evaluando resultados experimentando con otro modelo midiendo el desempeño evaluando los resultados si es con un proceso un poquito iterativo ya que llegamos a un buen. En donde la calidad y todo se cumple desplegamos la aplicación y después Ahora sí toca monitorear esto en producción y todo este ciclo se va a repetir Okay puede ser que la solución que liberamos el día de hoy el día de mañana requiera más funcionalidad entonces que volver a evaluar otra vez el caso de uso y vuelven a implementar todo esto bueno temas a considerar creo muy importantes no Uno evaluar las capacidades que va a tener dos identificar si tenemos los datos qué tanto acceso tenemos esa información en qué formato está Y qué calidad tiene con una de las temas más importantes requerimientos de cumplimiento regulatorios sería también algo importante porque puede haber casos en los que no podemos implementar nuestro caso de uso debido a restricciones no algún tema regulatorio muy bien y sobre el tema del impacto positivo que podría generar cuántos clientes vamos a beneficiar cuántas horas hombre vamos a ahorrar qué tanto nivel de satisfacción en el usuario final vamos a generar no como que hay que medir eso para ver si realmente vale la pena que arranquemos ese proyecto o si el enfoque que estamos considerando pues es como el adecuado ya pasamos esta etapa a ver si nos vamos a la parte de seleccionar modelo si por ejemplo yo estoy haciendo una aplicación para reservar vuelos Sí me imagino que la latencia tiene que ser Baja porque a veces estás en el aeropuerto quieres buscar un vuelo no puedo esperar mucho No pero sí quiero por ejemplo un modelo que genere imágenes productos de catálogo videos explicativos quizás la latencia puede ser menos importante Entonces eso es importante Qué capacidades tiene el modelo me va ayudar a evaluar Por ejemplo si soporta texto o imagen o es multimodal si soporta algún idioma en particular porque los modelos están entrenados para entender contexto en múltiples idiomas pero si no está considerado el idioma que yo estoy utilizando puede ser un problema no un modelo basado en instrucciones por ejemplo también podría ser un aspecto considerable luego cómo cómo optimizamos ese modelo que ya seleccionamos a través de técnicas de fronting Unity a través de hiper parámetros a través de contexto Sí todo eso va a ser que mejor el modelo o que probemos otro modelo evaluamos sí Y validamos una vez pasada esta etapa nos vamos ahora sí al. Mentación y la implementación para poder validar el desempeño tenemos que utilizar datos de prueba sí estos datos pueden ser dadas estándar que ya tienen bases de conocimiento y preguntas generales de muchas áreas de conocimiento para ver cómo se comporta un modelo versus otro o pueden ser mis propios datos sets de prueba en donde yo hago preguntas que normalmente mis clientes me hacen no Gabriel Cuánto cuesta esto Cuándo empieza Cómo Cuál es la política de devolución Qué pasa si llego tarde Qué pasa si no cumplo con el proyecto final sí esos Data sets yo los puedo tener ya de manera programática en librerías y después ejecutar testa automatizados para ver si le hago esta pregunta este modelo que me responde y luego ver la varianza que tiene la respuesta con eso ya puedo saber realmente qué tanto se mueve un modelo contra otro Y cuál es el que me da mayor precisión versus otro entonces este tema es muy importante y no solamente Aplica para aprobar nuestros modelos hay muchos benchmarks en el mercado que ayudan a testear el desempeño de los modelos No ya que tenemos Este modelo y una aplicación en producción es estar monitoreando constantemente Sí el modo de operación y esto puede ser obteniendo feedback de los usuarios puede ser viendo los blogs de la aplicación identificando métricas de desempeño utilizando por ejemplo clarify para ver qué tan justos están siendo las respuestas o las clasificaciones que estaban en mi modelo en producción Sí todo esto nos puede ayudar y aquí es donde entran por ejemplo este podemos ejecutar pruebas saber si pensamos ya en el contexto más un poco de box con cualquier aplicación que yo despliego en un servidor tengo que hacer pruebas puedo liberar nuevas versiones tengo que pensar en todo lo que tiene que ver con mleops o sea operaciones automatizadas Pines de integración continua de testing continuo de medición de métricas revertir un modelo a una versión anterior entonces todo esto va a ser súper interesante con ello tenga que monitorear este mis aplicaciones no tenemos por ejemplo en seis Maker y hay el model monitor y lo que hace es obtener métricas de calidad como por ejemplo el f1 score Como por ejemplo recall y precisión de mi modelo entonces lo que hacemos Es contra el datase de prueba estar considerando revisando las respuestas que está dando el modelo y ver si hay un Data drift también podemos hacer reviews manuales con personas utilizando mente ea y incorporar personas que nos ayuden a estar revisando constantemente que están como dentro del Loop revisando las respuestas que dan los modelos no muy bien y el último tema es justamente enfocado en los agentes de Petro un agente es una instancia que te permite ejecutar acciones sin intervención humana eso es lo que es un agente y realmente el gran Boom que hay ahorita en la industria y lo dice los reportes también de Mercado es agentes todo el mundo quiere implementar y a genética Entonces cuál es la idea de la gente que yo le dé una instrucción y la gente se encargue de resolver ese problema hasta llegar al final se retroalimenta a sí mismo y puede ejecutar herramientas para poder hacerlo entonces yo puedo implementar agentes también con bedrock imagínense que me creo hoy en bedrock un Bronx y este pronto es especialista en hacer búsquedas en internet Otro prompt que tiene herramientas para poder Acceder al sistema operativo puede ejecutar,ndos como se puede explotar,ndos linu y puedo hacer búsquedas en el sistema operativo y contextualizar con cosas que tengan una computadora y otra gente incluso puede ejecutar uso de computadora puede lanzar una máquina virtual ejecutar un navegador y ejecutar acciones dentro de ese contexto seguro dentro de ese playground entonces la gente podrá orquestar estos tres funciones o estas tres herramientas para poder llegar a un objetivo yo le podría decir ahorita no quiero que me ayudes a buscar en linkedin si las personas que podrían estar interesadas en mi curso día generativa este y después quiero que los guardes en mi sistema de en mi computadora en una lista en macdown Okay entonces el agente debe Rock va a tomar esta instrucción personal va a revisar Qué herramientas tiene va a decir ah tengo acceso al sistema operativo tengo acceso a hacer búsquedas web y tengo también la opción de poder levantar una máquina virtual con un navegador entonces combina las acciones que coordina las acciones de todos los diferentes agentes para poder llegar al resultado final y todo lo ejecuta dentro de un Loop Sí Mientras no esté se sigue retroalimentando sigue revisando los resultados de saber voy a alistar el sistema operativo veo que está vacío no tengo todavía nada Tengo otras dos herramientas búsqueda web y búsqueda de internet voy a levantar la máquina de web y ya que está voy a hacer una búsqueda web vamos a ir a linkedin vamos a buscar perfiles ya que tengo los perfiles los voy a guardar en el sistema operativo eso es lo que hacen los agentes sino más bien se van coordinando para poder ejecutar algún alguna actividad en particular Vean este ejemplo de aquí aquí el usuario quiere solicitar una recomendaciones para un viaje Entonces yo ya promete un agente y el agente tiene acceso a un modelo de lenguaje Entonces el agente puede tomar la decisión de ir a acceder primero a la base de datos de el catálogo de viajes si somos por ejemplo una agencia y damos viajes en 10 países distintos 20 ciudades vamos a extraer primero Esa información con esta información el agente puede tomar la decisión de ir a hacer cálculos Pues hay otra aplicación que se encarga de generar cálculos financieros para ver si el presupuesto está dentro de los parámetros que especificó el cliente no y después combinamos esto cómodo de lenguaje toda esta información se procesa constantemente y ya que si tiene una respuesta final se le devuelve el resultado al cliente entonces una manera de trabajar como de forma mucho más independiente Sí entonces Hoy estamos viendo también otro caso particular en el que vemos que bedrock nos podría ayudar también a resolver problemas pero que no solamente dependen de un pront sino más bien que están yendo mucho más allá a poder ejecutar más herramientas eso es lo que hacen los agentes no ese tema de asistente de políticas nos ayuda a verificar por ejemplo que todos nuestros procesos cumplan con políticas ya predefinidas en términos de seguridad no podemos utilizarlo en cute business estas políticas podrán definir por ejemplo que nunca revela información particular de cómo funcionan las áreas no podría por ejemplo también especificar una política de que no te dé recomendaciones de otras empresas Okay tenemos bedrock y sech me quiere ya y podemos aplicar todas estas políticas dentro de ellos Okay entonces Serán como los casos también podemos quedarnos aquí una aplicación sí aquí particularmente lo que nos dice es que podemos personalizar mucho más allá No desde el entrenamiento hasta el almacenamiento los modelos pueden guardar conversaciones y eso va incrementando sus storage y está creo que es la más importante el rendimiento que quiero que tenga el modelo al igual como funciona lambda que vienen de detectioner hablamos de lambda y decíamos que podemos adquirir capacidad en bedrock también podemos invertir Y adquiere capacidad Y eso hace que tenga un rendimiento mucho más alto y sobre todo bajar los costos también de uso también se puede como personalizar directamente desde acá no va a depender mucho del tipo de caso de uso del tipo de aplicación que quiere utilizar pero si se dan cuenta pues tenemos como muchas opciones distintas para poder resolver nuestras necesidades no muy bien y a ver últimas preguntas cuál es el principal propósito de los agentes en petrok lo que les dije ahorita porque su opción se irían aquí de okay muy bien secuencia de mucho en el día no eso es lo que hace Retro en general una gente lo que hace es orquestación sí los agentes como tal lo que van a hacer es darnos esa capa de orquestación o sea tomar las decisiones de qué se tiene que hacer y en función de las capacidades que tenga es la que está buscando justamente Sí esta documentación Está interesante y está fíjense los orquestadores entramos aquí yo hago una un Bronx y si mi agente tiene acceso a una herramienta que sea por ejemplo escribir código y otra herramienta que sea invocar una Api va a detectar la intención que tiene la instrucción original Entonces el orquestador va a tomar la decisión Ah esto parece a la Api que yo ya tengo voy a consultar las órdenes del cliente no Y la otra es Ah no tengo que escribir código para implementar esta solución se pones que vi código solamente es el orquestador el que va a tomar la decisión de qué vamos a hacer Sí entonces por ahí va justamente sí los agentes en bedrock pueden coordinar interacciones y algo interesante que tenemos en bedrock Es que yo puedo crear mis apis Entonces por ejemplo si yo tengo cinco microservicios unos para revisar órdenes otros para interactuar con inventario otras para hacer pagos otro para enviar mensajería este cada micro servicio a niveles su Api va a tener una descripción en particular Pues cuando yo implemento un agente en bedrock le voy a decir también Cuáles son estas acciones que puede ejecutar y en la definición Entonces el orquestador recibe la solicitud del cliente le dice quiero revisar mi orden que hice el mes pasado se va a decir a ver Tengo una Api o un micro servicio que es para revisar órdenes otra que es para revisar inventarios otra que es para facturar la probabilidad más alta es revisar la orden invoca la orden ve los parámetros que le tiene que pasar si no tiene los parámetros regresa con el cliente en un multiton y le dice claro Dame tu nombre y número de pedido claro Soy Gabriel y mi número de pedido es el sk001 perfecto los toma Y con esa información si ve que complementa ya la firma de la Api invoca la Api invoca el micro servicio que puede estar en Landa obtiene la información Eso es un rack si lo piensan por ese Jason devuelve y el orquestador le devuelve control sobre testadora ya tiene la información del pedido sí qué pasa si el cliente la pregunta Oye y quiero saber si ya pagué o Tengo un saldo pendiente a revisar la sapis va a decir ah tengo acceso un servicio que es para revisar pagos vas a revisar pagos y de la firma de los métodos y va a encontrar una que dice ver por ejemplo estatus de orden Lo invoca y le dice Oye cuál fue la cantidad que pagaste No pues $109 revisa y puede hacer esa lógica es más podría detectar que en la orden pagamos de más Sí entonces quizás el otro micro servicios para poder enviar correos electrónicos a alguien a una persona que nos ayuda a conciliar ese tipo de cuentas Vale entonces eso es lo que hace Petro con los agentes súper interesante muy bien perfecto compañeros pues les agradezco mucho por haber estado aquí el día de hoy siento que avanzamos bastante que hablamos de muchos temas sin todavía nos queda una sesión más si mal lo recuerdo la del próximo que va a ser justamente enfocarnos ya en la preparación del examen de practitioner así que pues Bueno este ya les estaré dando ahí alguna recomendaciones algunos tips así que pues bueno Espero que hayan disfrutado la sesión me dio mucho gusto saludarlos y ver que han sido bien constantes con estas sesiones y Bueno nos vemos el próximo lunes Sí a ver Jorge adelante bueno pues que tengan un excelente semana y muchas gracias a todos que tengan excelente noche Cuídense Muchas gracias